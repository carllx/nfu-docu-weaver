## 1. 引言

在[@2023mishraPromptingPseudocodeInstructions]的研究中（2023），提出了使用伪代码指令来提升预训练大型语言模型（LLM）的性能。本指南基于该研究，旨在帮助Prompt工程师设计更有效的伪代码提示。

## 2. 理解伪代码提示的优势

伪代码是一种非正式的编程语言，无法直接执行。它主要被用于帮助程序员以较简单和易懂的方式迅速沟通复杂的理念，进而加快程序员之间的理解速度。

即便我们现在可以理解自然语言，但大型语言模型的实验也显示，用伪代码进行交流可能会得到更好的效果。这表明开发者应当利用伪代码的清晰和简练来撰写更为有效的提示语。

- **结构化提示**：伪代码的结构化性，如函数声明、文档字符串（docstrings）及内联注释，有助于模型识别任务的关键步骤, 帮助模型更精确地理解指令。

- **减少歧义**：与自然语言相比，伪代码的表达更精确，极大地减少了模型解释指令时的歧义问题。

- **性能提升**：在分类任务中，使用伪代码指令可使F1分数平均提升7到16个百分点，在所有任务中还可使ROUGE-L分数相对提高12到38%。

实验结果如下：

- **分类任务**：伪代码提示在分类任务中展现出明显的性能提升。
- **问答任务**：特别是在多项选择问题（MCQ）方面，伪代码提示的表现优于自然语言提示。
- **语言生成任务**：在某些情况下，伪代码提示也能提高语言生成任务的性能。研究结果显示伪代码指令能在语言生成任务中带来性能提升。


## 3. 设计伪代码提示的示范以及步骤
(Source:  [github.com: pseudo-code-instructions/instructions at master · mayank31398/pseudo-code-instructions](https://github.com/mayank31398/pseudo-code-instructions/tree/master/instructions))

示范: 
```python
I will provide a piece of pseudocode please predict its output only need to return the result of the output omit the reasoning execution process.

def generate_sentiment(sentence: str) -> str:
    """
    对于给定的句子，任务是预测情感。如果是积极情绪返回 "positive"，否则返回 "negative"。
    
    参数：
    sentence (str): 输入句子
    
    返回：
    str: 输入的情感
    """
    # 预测情感
    if sentiment_is_positive(sentence):
        return "positive"
    else:
        return "negative"

>>> generate_sentiment(
    "that has a charmingly bourbon air."
)
```

### 3.1 定义函数原型

- **描述性名称**：为函数提供一个描述性名称，总结要执行的任务。
- **参数和返回类型**：包括所有输入变量及其数据类型和返回类型。

### 3.2 编写DocString
提供任务的自然语言描述，这有助于模型更好地理解任务的具体要求。
- **任务描述**：使用自然语言详细描述要执行的任务。
- **参数列表**：列出函数接收的参数及其类型。
- **返回值**：说明函数返回值的类型。

### 3.3 构建函数定义

- **子任务函数**：在函数定义中，使用子任务函数描述解决特定任务的步骤。这些子任务函数通常不定义，但应具有描述性名称、参数和变量。
- **内联注释**：在必要时，添加内联注释说明子任务函数的作用和参数的角色。这不仅有助于人类理解，也可能帮助模型更好地把握任务的上下文。

### 3.4 预处理器

- **输入解析**：由于伪代码提示期望以参数形式接收输入，**需要一个预处理器来解析输入数据。**

## 4. 注意事项

1. **明确任务目标**：伪代码应清晰定义主要函数的原型，包括函数名称、输入参数及其数据类型、返回类型。这有助于模型理解任务需求。
1. **简洁性:** 伪代码应简洁明了，避免不必要的复杂性，这有助于模型更有效地处理和响应Prompt。
1. **测试模型特性**：不同模型可能对伪代码的解释和执行有不同的反应，设计时应考虑模型的特性和训练数据。应在不同的大型语言模型（LLM）上进行测试，比较其与自然语言Prompt的性能差异。
2.  **迭代优化**：基于测试结果，对伪代码Prompt进行迭代优化，以提高模型在特定任务上的表现。
3. **任务类型适配:**  根据任务的不同类型（如分类、问答、语言生成等），调整伪代码的结构和详细程度，以最大化模型性能。