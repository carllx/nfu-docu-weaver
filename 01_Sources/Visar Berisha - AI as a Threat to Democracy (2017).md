---
TL;DR:
---


---

# AI as a Threat to Democracy: Towards an Empirically Grounded Theory  

Thesis · December 2017

DOI: 10.13140/RG.2.2.33108.24960  

CITATION
1  

READS
7.309  

1 author:  

![](https://i.imgur.com/YjYWOA0.jpeg)  

Visar Berisha
Uppsala University
2 PUBLICATIONS 1 CITATION  

SEE PROFILE  

![](https://i.imgur.com/yeTDU7y.jpeg)  

# UPPSALA
UNIVERSITET  

# AI as a Threat to Democracy: Towards an Empirically Grounded Theory.  

Visar Berisha  

Master Thesis, Political Science
Department of Government, Uppsala University
Autumn 2017
Supervised by Professor Joakim Palme  

# Abstract  

Artificial intelligence has in recent years taken center stage in the technological development. Major corporations, operating in a variety of economic sectors, are investing heavily in AI in order to stay competitive in the years and decades to come. What differentiates this technology from traditional computing is that it can carry out tasks previously limited to humans. As such it contains the possibility to revolutionize every aspect of our society. Until now, social science has not given the proper attention that this emerging technological phenomena deserves, a phenomena which, according to some, is increasing in strength exponentially. This paper aims to problematize AI in the light of democratic elections, both as an analytical tool and as a tool for manipulation. It also looks at three recent empirical cases where AI technology was used extensively. The results show that there in fact are reasons to worry. AI as an instrument can be used to covertly affect the public debate, to depress voter turnout, to polarize the population, and to hinder understanding of political issues.  

"Follow the money"
All The President's Men, 1976.  

"Follow the data"
The Guardian, 2017.  

1. Introduction 6 2. Motivation & Research Question 7 3. Methodological Approach 10 3.1 Political Theory, Thematic Analysis & Grounded Theory 11 3.2 Comparative Case Study 12 4. Theoretical Analysis 13 4.1 Democracy 14 4.1.1 Theoretical Approaches 14 4.1.2 Ideal vs. Non-Ideal 17 4.1.3 Typologies and Types 17 4.1.4 International Democracy Indices 19 4.1.5 Definition 20 4.2 Artificial Intelligence 21 4.2.1 History and Significance 22 4.2.2 Current State and Development 26 4.2.3 Machine Learning and Algorithms 27 4.3 Elections & Campaigns 30 4.3.1 Free and competitive 31 4.3.2 Accountability & Legitimacy 31 4.3.3 Campaigns 33 4.4 Theoretical Framework & Hypotheses 34 5. Empirical Analysis 38 5.1 Obama 2008 & 2012 38 5.2 Brexit 40 5.3 U.S Presidential Election 2016 43 5.4 Discussion 45 5.4.1 Hypothesis 1: Power Balance 45 5.4.2 Hypothesis 2: Debate and Agenda 47 5.4.3 Hypothesis 3: Enlightened Understanding 49 5.4.4 Hypothesis 4: Voter Turnout 50 6. Concluding Remarks 52 7. The Prospects of AI in Political Science 54 References 56  

# Figures and Tables  

Figure 1. Cunningham's schematic framework of the usage of democracy in theory. 15

Table 2. Dahl's schematic framework of how democracy is conceived in democratic theory. 16

Figure 2. Graph of exponential vs. linear growth. 24

Figure 3. Key milestones in human history (Kurzweil). 24

Figure 4. Key milestone in human history (other scholars). 25

Figure 5. The rising tide of AI capacity. 26

Figure 6. Schematic representation of machine learning. 28

Figure 7. Semantic network of Brexit hashtags. 42

Figure 8. Ideological distance of the American population. 48  

# 1. Introduction  

Tay was a program developed by Microsoft in 2016, which used machine learning to emulate a teenage user on Twitter. In the first few hours it looked like a success, with uplifting and positive tweets from a seemingly friendly robot which happily sent her first greeting saying "helloworld world!!" (Hayasaki, 2017, p.40). Only hours in, however, it was making racist and sexist remarks, forcing Microsoft to pull it off, stating that they "take full responsibility for not seeing this possibility ahead of time" (ibid.).  

This story is telling in many regards. First is that artificial intelligence (AI) can be used to emulate people in the digital world, communicating and learning from them and as a result, develop and form something that resembles a personality. The other lesson is less optimistic, it had developed in a manner which its creators had not foreseen, forcing them to withdraw it from the web. It seems that this is symbolic of technology in general which develops through trial and error. However, as philosopher Nick Bostrom (2012) reminds us, when it comes to AI we only have one chance to get it right. As we will see later, what Bostrom is talking about when he makes this claim is artificial general, or human level, intelligence, which has the capacity to develop itself and probably transcend human capacity, but can the same be said of lower level AI? I suspect that the thought merits some consideration, although it by no means represent the same existential threat that worries Bostrom and other AI-safety advocates. The general idea is perhaps best expressed by Marshall McLuhan, a pivotal figure in media theory, who is credited with saying "we shape our tools, and thereafter they shape us" (Pariser, 2011, p.6). Indeed the examples of this are many, from cars to social media, technological advancements shape our lives. When it comes to AI, this becomes even more evident, with technology that appear to 'think', to understand natural language, to interpret visual inputs and to analyze patterns and correlations in large data-sets, it possesses the capacity to penetrate every aspect of our lives and to radically reshape our world (Kurzweil, 2005).  

The present study$^{1}$ deals with one particular application of AI, namely its usage in political contexts. As a student of political science, this both intrigues and worries me. Technology itself is morally neutral, it is instead determined by the user,  

and this applies to AI as well. On the one hand, it presents an opportunity for better research, a tool for social movements, an analytical instrument for journalists and civil society which can increase the transparency and accountability of political leaders and so on. On the other hand, I believe, it has the potential to threat core democratic institutions, which is not only pivotal for our freedoms and rights, but also a fundamental part of our culture. To understand this we need to understand AI as an instrument of power, its big data analytical capacity produces astonishing results, enabling its user to discover highly detailed information about individuals in a quite accurate manner. This information can be used either to sell clothes or to push certain political narratives, and it is available for whoever has the money or the technological skills to utilize it.  

The initial instance which triggered my interest in this subject was reading about the 2012 Obama campaign, which used big data analysis to construct advertising campaigns targeting voters on an individual level (Domingos, 2015). Knowing that AI has emerged as one of the most exiting technical fields in the last few years, attracting both investments from cooperations and brilliant minds, I wondered how this strategy had developed since then, and weather it contains problematic elements from a democratic point of view. The aim of the present study is to explore precisely this, using a primarily theoretical approach to draw initial hypotheses, but also testing them empirically by looking at three distinct cases. As such, this thesis should be regarded as a first step toward a theory of explaining the interaction of AI and democracy. It is therefore neither exhaustive nor conclusive, but offers a first attempt to uncover possible tensions erupting from this interaction. Its contribution is thus twofold. On the one hand it problematises democracy in the light of this emerging technology and gives a first assessment of its effect on democratic principles, and on the other it hopefully raises the awareness of AI among political scientists and invites them to consider it in their intellectual work.  

# 2. Motivation & Research Question  

The central aim of social science is, as its name implies, the study of society and all its intricate aspects and dimensions. Political science is a subfield of social science and deals with the governance of a state, of the impact of societal, cultural, and psychological factors, all surrounding power as the element of central importance (Political Science, 2017). As was mentioned in the introduction, I view technology as  

an instrument of power, in particular if that technology is not widely dispersed among the population. The impact and significance of that technology, and its subsequent effect on the power structure of a society, is determined primarily by its sophistication and potency. AI is not a novel approach in computer science, but it is now, after decades of research and development, starting to reach a level of maturity where it can be beneficial to the broader mass, and as such economically sensible for corporations to invest in (Tegmark, 2017). The result, as I understand it after reviewing the relevant literature, is a sophistication of AI to such a degree that it possesses the power to completely transform our lives in the years and decades to come. This can be, and in fact is, debated, as we will see below, however regardless of the speed by which it developed, the mere capability it presents motivates scientific inquiry.

Perhaps it is due to its relative novelty in the mainstream economy, or its intimidating technologic complexity, or a combination of both, but social science has not, in my opinion, dealt sufficiently with the potential consequences which AI presents. I think social scientists view this as an issue outside their field of study, it is an issue for physicists and engineers since it is, at its very core, technological. AI has been used as a method for data-analysis by some social scientists (Hindman, 2017), and some have used it as a predictor for political outcomes by looking at social media behavior for example (Kristensen et al., 2017), but only a few have discussed the potential disruptions it might represent to our societies. The aspect which has received most attention in this regard, is the potential it presents in automizing labour, rendering human workers superfluous (Autor, 2015; Ford, 2015). However, and unfortunately, this has received only limited attention by social scientists, instead it is the physicists, the philosophers and the economists who have been at the forefront of this discussion. This study presents a modest attempt to include the discussion of artificial intelligence in the realm of political science.

A reasonable question to raise at this point is where exactly does the unique potential of AI lie? A thorough answer will be given in later sections, for now it suffices to say that it is important precisely because it mimics human intelligence, creativity and even intuition. It is developing at an impressive exponential rate, gaining a lot of attention and is increasingly financially beneficial, meaning that it will continue to receive funding (some have called it a technological arms race) (Bostrom, 2014; Tegmark, 2017). Thinking machines, to use a preliminary and somewhat provocative label, will increasingly influence every aspect of our lives and  

societies, from the digital personal assistants and optimized search results, to self-driving cars and automated factories, the technology stands to penetrate every segment of our society. As a political scientist, I am interested in what this will mean to our political life. More specifically, as mentioned above, the primary aim of this thesis is to study the impact of AI on our democratic institutions. The Obama campaign in 2012 used machine learning and big data from, among others things, social media, to determine every aspect of their strategy. The computer savvy and clever young campaign workers were highly successful in not only mobilizing, but also convincing voters to give Obama their support (Domingos, 2015). This represents a new era of political campaigning, based heavily on individualizing the voter and tailoring the communication accordingly. However, does this pose a threat to democracy? On an intuitive level it at least raises some concerns. For example, will actors be able to use AI to miss-inform voters, to push the public discourse in illegitimate ways, to propagate and spread racist, sexist and other adverse ideas, will it further polarize the debate and consolidate filter-bubbles and echo-chambers? The concerns expressed here are not rooted in a reactionary suspicion towards AI, but rather on an academic interest to find potential problems that this presents. AI can, undoubtedly, be beneficial to democracy, again it is morally neutral, but we need to continuously examine it in order to ensure that it develops toward a beneficiary end.  

Due to the scope of current study, it will be limited to study one particular aspect of democracy: elections. More specifically, it will look at the campaigns preceding the elections. There are two reasons for this. One is that elections constitute a fundamental, although not exclusive, aspect of democracy. The second is that, as of now, AI seems to have the greatest utility value precisely in elections, as it can be used to engender support, among other things. Since my main interest is in how power is distributed, I will look at those on whom ultimate power is normally located, politicians and their parties. Taken together thus, the aim is to study the actions of politicians during election campaigns. The research question is thus as follows:  

RQ: Does AI constitute a threat to democracy's core principles when used in political campaigns preceding an election?  

Some clarifications are perhaps in order. First, the word threat should be understood broadly, it does not necessarily mean severe or debilitating, but can rather increase  

the democratic deficit which already exist in non-ideal democracies (Dahl, 1989). Second, there might be more than one singular threat, or rather the threat can have many dimensions. Thirdly, AI should be understood as an instrument, among others, utilized in the political campaign; it does therefore not, in itself, pose a threat. Finally, the period which I am concerned with is the time leading up to an election, where the political dialogue increases in society and where politicians strive to gain support from voters.  

# 3. Methodological Approach  

The nature of the research question encourages a philosophical inquiry primarily. Being one of the few studies which seeks to study the emergence of AI from a political science perspective, it is perhaps a necessary approach. I view this study as an effort to uncover broadly the interaction between artificial intelligence and democracy, to see if and where tensions appear and to try and explain them, but not to study these in detail or try to prove them significance empirically, although such an inquiry is, to a lesser degree, also present. It is thus first and foremost a study in political theory.  

This requires three things. First, democracy needs to be analyzed on a normative and conceptual level, in order to form an understanding of it which will be the foundation on which my analysis rests. Second, a discussion of artificial intelligence is necessary, approaching it as a concept, as a reality and as a technical capacity. Thirdly these two elements need to be combined into a coherent theoretical thought. The aim of this is to view the identified dimensions of democracy in the light of AI technology. This should be viewed both as a preliminary theoretical analysis guided by the research question and as a theoretical framework guiding the ensuing empirical case study.  

The methodological approach is therefore twofold. The first is primarily deductive in nature, where I draw logical conclusions from the theoretical discussions on democracy and the techniques of artificial intelligence. This will enable me to form hypotheses for the second part the study, which is to test the hypotheses empirically, by studying suitable cases. The aim here is to get an initial assessment of how prevalent the theoretically deduced conclusions are in real-life instances. It thus presents and opportunity to both assess my initial suggestions and to, through a inductive process, reformulate my hypothesis and theoretical  

conclusions. Due to the scope of this paper, however, I will primarily focus on the former, and invite other researchers to engage in the latter. Taken together, this study should be viewed as an initial step toward a theory considering AI in democracy.  

# 3.1 Political Theory, Thematic Analysis & Grounded Theory  

List and Valentini (2016) make a distinction between political science on the one hand, which is a positivist approach studying actual political phenomena, and political theory which is more normative and evaluative in nature. However, they also distinguish political theory from moral theory, asserting that the former can be seen as subcategory of the latter, which deals specifically with political issues. I accept this distinction and understand that it places my study between political science and moral philosophy. However, it is not strictly in the domain of political theory; it deals with a specific political process, the election process, and includes an comparative analysis of empirical cases.  

Being primarily philosophical in nature, the analytical method will be "argument based...[emphasizing] logical rigour, terminological precision, and clear exposition" (ibid., p.1). What this means is that my arguments will be constructed from logical deduction, where I, through a normative and conceptual analysis of democracy and a inspection of the technical capacity of AI, draw certain premises that, if true, support my theoretical conclusions. This process will thus enable me to form a number of hypotheses, the soundness of which will be tested through a brief review of three empirical cases. Here we need to make a distinction between the validity of deductive arguments, which is ensured if the premisses are true, and the soundness of the argument, which is determined by the degree to which the premisses are true. The empirical analysis can be viewed as a test of the soundness of the hypotheses, but also an opportunity for inductive reasoning, where the cases might illuminate aspects previously overlooked (Baggini & Fosl, 2010; IEP, 2017). However, as mentioned above, this lies outside the scope of the present study and thus presents an opportunity for further research.  

I view research methods as a set of tools to be used in order to explore the issue at hand, my research is therefore problem-driven, rather than determined by a specific method (Shapiro et al., 2004). What is important in this regard, is to be transparent and conscious about which methods you use and to use them systematically and consistently throughout the research. As such, I draw inspiration from primarily two, broadly interpreted, methods. The first is a thematic analysis  

where the analytical process is guided by categories identified by the researcher. These categories or themes can be constructed either from empirical data or theory (Bryman, 2012). I identify them theoretically and they constitute the foundation on which the hypotheses are formulated. This process enables me to categorize my ideas and organize my research, and also to crystallize the findings. The second is grounded theory, where the aim is to discover theories through a systematic collection and analysis of empirical data. This is contrasted to logically deduced theory building and encourages a lower level abstraction in the process of theory formulation (Glaser & Strauss, 1967). I view the latter approach primarily as an inspiring guideline, helping me to conduct the comparative case study, and to draw conclusions which are supported by empirical observations. In other words, the insight that grounded theory offers is that it helps scholars avoid 'the ivory tower' of academia, and instead forces us to formulate ideas and conclusions which are grounded in the real world.  

# 3.2 Comparative Case Study  

A case study is a research design approach where the complexity and nature of a specific case is studied intensely through the collection and analysis of empirical data. The goal is to understand a specific case, a location, a community, an organization and so on, by collecting data about it extensively and analyzing it systematically (Bryman, 2012). A comparative case study includes two or more cases. The goal here is to discover by contrasting, to study similarities and uncover patterns which might be used to either test or develop theories and hypotheses. Considering the broadness of the research question and also the lack of research of the subject at hand, I consider the cases chosen to be exploratory first and foremost, and to a lesser degree descriptive, while no attempt is made to explain them in detail (Yin, 2003; Mills et al., 2010).  

The cases chosen in this study are both contemporary and, I believe, of such nature that they will contribute to our understanding of the utility of AI in election processes and possible problems that might emerge from its usage. The cases are the following:  

i) The Obama campaign 2012

ii) The Leave-campaign, Brexit referendum 2016

iii) The Trump campaign 2016  

The first case represents a new beginning in AI aided political campaigning. Obama was the first to see the power of big data analysis in 2008 and four years later, his team improved the method which was a crucial part in his re-election (Issenberg, 2012). The full magnitude of AI in the second case remains to be seen, but early report show that it played a big role, but also, and crucially, the method first introduced by the Obama campaign eight years earlier, was perfected in important ways, making the approach both more sophisticated and effective (Cadwaldr, 2017a). Finally, the third case looks at one of the most surprising political happenings in later years: the Trump victory in the 2016 U.S presidential campaign. Here the same methods used in pro-Brexit campaign was again put in use, but an important difference is that machine learning algorithms and big data analysis are suspected to have also been used covertly by organizations with connections to the Russian state (ICA, 2017; Bunch, 2017).  

As mentioned previously, these present an initial test of my hypotheses, but are not studied to the extent needed to draw any generalizable conclusions. What is needed is an iterative process, similar to the one advocated by grounded theory and much larger in scope, where the collection and analysis of data determines one another, with the aim to formulate a theory established in empirical data. This is, once more, outside the scope of this thesis. What I aim to offer here is an initial step toward theorizing the impact of AI in the democratic process and hopefully an inspiration for further research.  

# 4. Theoretical Analysis  

As mentioned in the introduction, a central part of this study is to treat the subject defined in the research question theoretically. This means analyzing the central concepts, democracy, AI and democratic elections, and to combine these into a coherent framework from which we can draw preliminary hypotheses. By preliminary I wish to convey that the conclusions reached in this chapter by no means are exhaustive; the empirical analysis will undoubtedly raise new issues and concerns which invites to reconsideration in further research. This is outside the scope of this study, even though it will be discussed briefly in the concluding remarks.  

This section provides first a conceptual and normative discussion on democracy, continuing with a short description and discussion on AI and democratic elections. Finally, these will be combined into a theoretical framework.  

# 4.1 Democracy  

As the primary focus of this thesis, it is necessary that democracy is discussed and problematized on a conceptual level, in order to arrive at a definition which is well suited for the study at hand. A good place to start, before delving into and discussing in detail the complexities of term, is perhaps to establish that democracy, as a concept or phenomena, is far from clearly defined in any one singular way. On the contrary, it is multidimensional, complex and varies in meaning in relation to its usage and interpretation. As such it is, as some philosophers have called it, an essentially contested concept, often imbedded in rival theories (Cunningham, 2002; 3). For example Gamal Abdel Nasser and Rafael Trujillo both proclaimed to lead democratic countries, even though their power rested in military dictatorships. Similarly the People's Republic of China and the Soviet Union both proclaimed to be peoples democracies, the people being the classless mass envisioned at the end of the revolution (Crick, 2002). This signalizes the near universal attraction that the term seem to posses, according to political theorist John Dunn because it is what is virtuous for a state to be (Hoffman & Graham, 2006). However, a term which encompasses all meaning contains, in practice, none. This cannot be said about democracy; despite its various interpretations, certain aspects, such as universal adult suffrage and free and reoccurring election are central to the term. Nonetheless, the varied ways that democracy is understood and used mirrors its complexity, and in order to arrive at an understanding of it that can be used in this thesis, we need to first analyze it conceptually.  

# 4.1.1 Theoretical Approaches  

In democratic theory, the term is used in various ways by scholars from different disciplines which focus on specific aspects of democracy, albeit not always in a transparent and rigorous way. In order to understand its multidimensional character, therefore, we need to distinguish these different approaches. Here I will use two primary sources which have developed insightful schematic frameworks explaining the different methodological and analytical approaches in democratic theory. The first, shown in figure 1 below, developed by Frank Cunningham (2003) categorizes  

the usage of democracy in academia into three broad dimensions; the first strain deals with the normative aspects of it, the second deals with descriptive questions of democracy where research focus on the procedural and functional aspects, and lastly the semantic strain, which deals with the meaning of term.  

Figure 1. Cunningham's schematic framework of the usage of democracy in theory (2003, p.11).  

![](https://i.imgur.com/8o9thzj.jpeg)  

Naturally this stark distinction is hard to maintain in practice as the different approaches overlap and sometimes converge, and often scholars engaged in democratic theory are themselves either unaware of these differences, not transparent enough about which one they focus on or fail to follow this delineation rigorously throughout their work. For example, Joseph Schumpeter had a minimalist view of democracy, defined merely as an institutional arrangement where power is gained through competitive struggle for the people's vote. This is a descriptive definition. However, when he seeks to rank democratic governments, he does so by looking at their their success, but success in what regard? His minimalist definition requires him to rank all governments who periodically compete for the public vote as equal, regardless of the policies they produce. Success, thus, is contingent on some normative understanding of democracy, a distinction that Schumpeter seemingly have difficulties of maintaining (ibid; 13).  

The second framework comes from Robert Dahl (1989) and is similar to the distinction that Cunningham draws. The imagery that Dahl uses to describe the field of democratic theory is that of a large three-dimensional web, consisting of different interlinked strands. Table 1 aims to clarify this intricate web by placing some of the  

most important aspects of democratic theory on a two dimensional table. Aspects of democracy placed on the horizontal axis range from philosophical considerations on the left, to more empirical ones on the right, and mixes of both in between. The vertical axis measure the critical level of the different approaches found in democratic theory.  

![](https://i.imgur.com/Bvv4rul.jpeg)  
Table 1. Some Aspects of a Theory about the Democratic Process (Domain: Associations that satisfy the requirements of (2) below)   
Table 1. Dahl's schematic framework of how democracy is conceived in democratic theory (1989, p. 7).  

*Deliberately ambiguous; may mean necessary to, sufficient for, or increase (significantly) probability of . . .  

A couple of things are important to point out here. First, we can see that Dahl draws up two main dimensions of democracy as it is used in theory, philosophical and empirical, or in other words, and similar to Cunningham, normative and descriptive. However, these are not self-contained categories, instead any use of term is thought of as being somewhere along the line of the two ideal extremes. Second, we need to keep in mind that the table, according to Dahl, displays only one possible way of understanding democratic theory, reminding us that it is a "large enterprise — normative, empirical, philosophical, sympathetic, critical, historical, utopianistic, all at once — but complexly interconnected" (ibid; 8).  

It should be clear by now that we need to think in terms of approaches and frameworks when we discuss democracy, at least on a theoretical level, and be aware of which approach we employ when we study it. Before determining it for this paper, it is important that we discuss other conceptual aspects of democracy.  

# 4.1.2 Ideal vs. Non-Ideal  

When discussing democracy, or any ideology for that matter, it is important to distinguish between its ideal, often constructed as part of an analytical framework, and what we might reasonably expect in the real world. This distinction between an ideal and realist notion of a democracy is crucial because it determines how we approach it analytically. For example, if we understand democracy by its literal meaning - demos meaning people and kratia meaning rule or authority (Dahl, 1989; 3) - then any system professing to be democratic can only be viewed as such if all political power in fact is placed in the people. But this is problematic, for example how will the procedure in such a system look like in practice? Political representation avert from this notion since power will be concentrated in the hands, not of the people, but of their representatives. Dahl, clearly aware of this observation, crystallizes this by distinguishing democracy as an ideal from actually existing political systems containing institutions and procedures resembling or in tune with the ideal (ibid; 218). Keeping this in mind is crucial when constructing the analytical framework so that we, in the words of Dahl, do not compare or confuse ideal oranges with real apples (ibid; 84).  

# 4.1.3 Typologies and Types  

Being a multidimensional and highly complex concept, democracy has been interpreted in a variety of ways. Its near universal appeal makes it particularly prone for prolific interpretation with actors lifting different aspects of it as particularly important. Although not central to this study, we will briefly touch upon some of these shortly, as it is of interest when formulating a definition. First, however, we need to take a step back and review the efforts that have been carried out to classify and categorize the different understandings of democracy. I will discuss two here which I think are of particular interest in this context. The first was formulated by Arend Lijphart, where he aimed to classify democratic systems based on two structural components: weather a society is homogenous with regard to religious and ideological convictions and weather the electoral system is majoritarian or representational. Later he developed a slightly different typology where the electoral system component was replaced by a political system component which measured the level of centralization of electoral power. These two typologies were developed for different purposes, the first used to measure stability while the second to measure performance (Doorenspleet & Pellikaan 2013).  

A second typology, developed by Albert Weale (1999), takes a different approach. The first classificatory step distinguishes direct democracy from indirect, or representative, democracy. The second step further divides these into subcategories. Direct democracies are divided in unmediated popular government and party-mediated popular government, while indirect democracies are divided into representational government, accountable government and liberal constitutionalism. The main difference between these is how representation is conceived. In the first category, representation has a value in itself since it seen as a mirror of public will, while in the second representation is seen merely as a political mechanism where the democratic value lies in the reoccurring elections. Similarly, liberal constitutionalism places the democratic value not in representation itself, but in the power that the public has to throw out a political elite whose actions do not correspond to their will or who overreach their power (ibid.).

The purpose of this short discussion on typology is to bring attention to the way scholars have sought to systematize the thinking around democracy. In this regard it is informative since it asserts its multidimensional and intricate nature. In order to both exemplify this and to further discuss some of the most important aspects of democracy, I will briefly discuss some of the central types of democracy prevalent in literature. Liberal democracy is perhaps the most distinguished strand and is often used when describing democratic political systems (Cunningham, 2002). In fact, some claim that liberal democracy should be distinguished from other types since it requires the protection of certain liberties and rights, not only for those considered to be part of the 'people' but for all, and this, they claim, is what we intuitively understand to be democracy (Plattner, 2005). The general will is thus limited, in order to protect the liberties of minorities from the majority (Cunningham, 2002). Deliberative democracy is another school where the legitimacy of political actions primarily derives from a broader dialogue and discussion, as opposed to merely electoral results or the outcomes of policies (Gupta, 2006; Cunningham, 2002). Participatory democracy, as the name implies, places the participation of citizens in the center of the democratic process. In contrast to other forms of democracy, which have a more narrow view of citizen participation, citizen engagement constitutes the very essence of democracy according to this view (Nelson, 2010; Gupta, 2006; Dahl, 1989; Cunningham, 2002; Goodin et al., 2007; Crick, 2002). These are only a small sample of the many different ways democracy  

has been conceptualized, the point, however, is to show where the democratic value and function is placed.  

# 4.1.4 International Democracy Indices  

There exists several institutions and organizations which create periodically updated indices measuring countries democracy levels, or certain aspects of it. To mention just a few there is the Bertelsmann Transformation Index, the Democracy Barometer, the Economist Intelligence Unit index, the Freedom house measure and the newly formed V-Dem institute which publishes the most extensive collection of democracy indices (Coppedge et al., 2017). For this reason I will focus on the latter.  

A fundamental feature of democracy, according to V-Dem, is the electoral principle; without reoccurring elections, they correctly claim, we cannot speak about a system being democratic. But this does not suffice; there are other, non-electoral, elements which according to some are central to democracy. The institution lists six of these principles: the liberal principle which includes provisions protecting the rights and freedoms of individuals, the majoritarian principle which demands that the will of the majority determines political outcomes, the consensual principle contradicts, in a way, the majoritarian principle and is the idea that inclusivity and consent should be maximized in the political process, the core idea of the participatory principle is to activate people politically in addition to electoral participation, the deliberative principle prescribes political decisions to be based on broad and reason-based discussion, finally the egalitarian principle encompasses the idea that all should have equal opportunities to participate in the political process, both by law and in practice and without being limited by factors such as socio-economic status, gender, ethnicity, religion and so on (Coppedge et al., 2017). By contrast, Freedom house, which does not measure democracy per se but is often used as a measure of it, scores countries according to indicators of political rights and civil liberties. In the former category the electoral process, political pluralism and participation is included while in the latter freedom of expression and belief, associational rights, rule of law and personal autonomy is included (Freedom House, 2016). The Economist Intelligence Unit's index of democracy is another well-used assessment of countries democratic levels. Similar to V-Dem, free and fair elections are seen as fundamental to democracies, but an additional five principles are included: electoral process and pluralism, civil liberties, the functioning of government (implementation of democratic decisions), political participation, and political culture (accepting the election outcome,  

demanding accountability, engaging in debate, refraining from violence etcetera) (The Economist Intelligence Unit, 2015).  

As a central concept in this thesis, a fairly comprehensive review of democracy, both as a concept and as a theory, has been necessary. For the remainder of this section, a definition will be formulated, based on the insights offered above.  

# 4.1.5 Definition  

From the discussion above, I conclude that there are four main methodological approaches in the study of democracy; semantic, normative, procedural and policy. It should be clear from the onset, and following the logic of William Nelson (2010) who asserts that issues of justification and definition cannot be isolated but combined in what he calls "theories of democracy" (p.2), that these approaches cannot be disconnected in any strict sense. However, I think this categorical division should act as a guiding principle going forward.  

Following Dahl's (1989) approach in his study, I conceive democracy as a "process of making collective and binding decisions", as opposed to "a distinctive set off political institutions and practices, a particular body of rights, a social and economic order, [or] a system that ensures certain desirable results" (p.5). However, as Dahl also claims, these are interlinked in important ways and cannot be wholly isolated from one another. Notwithstanding, the definition that will be used in this thesis is the following: democracy is a political process where the members of an association collectively determine the rules and laws under which they obey.  

Notice that this is merely a descriptive definition of democracy, it makes no normative claims and does not specify what outcomes are desirable. However, Dahl's definition rests on certain normative claims:  

i) the Principle of Intrinsic Equality which states that all human beings are equal in some fundamental way, and that no one is entitled to subject another to his or her authority, and  

ii) the Presumption of Personal Autonomy which states that in the absence of a compelling evidence showing to the contrary, everyone should be assumed to be the best judge of his or her own good or interests, justifies the adoption of  

iii) the Strong Principle of Equality which states that every adult member of an association is sufficiently well qualified to participate in making binding collective decisions that effect his or her good or interests.  

Dahl concludes that, if the Strong Principle of Equality is to be respected, a democratic process is required. From this he formulates five criteria which a political process must fulfill:  

i) effective participation throughout the process by ensuring adequate and equal opportunity to express preferences and influence the agenda,  

ii) voting equality at the decisive stage,  

iii) enlightened understanding of the issues which are the subject of a decision,  

iv) equal opportunity to control the agenda of the democratic process and finally,  

v) inclusiveness of all adult members of the association, or demos, with the exception of transients and others who fall outside the realm of the collective decision.  

Keep in mind that democracies fulfill these criterion to various degrees, they are thus principles of an ideal democracy. Also, these criteria correspond to various degrees to the different types of democracies discussed above. For example, the requirement of effective participation is similar to the one that adherents to representative democracy maintain is of central importance. Similarly, many of the dimensions that V-Dem measures, like the level of deliberation and the equality of voters, can also be found in Dahl's criterion.  

# 4.2 Artificial Intelligence  

Intelligence is the cornerstone of human civilization. It is the single most important attribute which distinguishes us from other creatures inhabiting the planet, a capability which has enabled us spread across the world, which has allowed us to master nature, build cities and empires and transcend our biological limitations with technology (Harari, 2014). It is thus not hard to understand the mesmerizing appeal that the idea of artificial intelligence possesses; it represents an expansion not only of our technological capabilities, but our understanding of life and humanity itself.  

The meaning of AI is, at first glance, fairly straightforward; artificial denotes that it is synthetic or man/woman made. The second word is intelligence, something most of us have an intuitive understanding of, but which is not fully understood  

neither by scientists or philosophers. Tegmark (2017) defines it as the ability to accomplish complex goals, well aware that is broad but, he claims, necessarily so. Intelligence is a multidimensional concept, encompassing many different traits and capabilities, such as learning, self-awareness, problem solving and so on. Some machines, for example simple calculators, far exceed human capabilities, while others, for example those designed for image or speech recognition, are inferior even to that of small children. Thus the ability to accomplish complex goals might be limited to certain ends, what is called narrow or weak intelligence or a vast number of goals which is called broad or general intelligence. Exceeding the human level is sometimes called super-intelligence and the moment in time when this occurs is called the singularity or the beginning of an intelligence explosion (Tegmark, 2017; Bostrom 2014; Kurzweil, 2005).  

Artificial intelligence is therefore not a concept with a singular meaning, but, like democracy, varies in relation to how it is used. AI in a narrow sense is already an important part in many of our everyday tools, such as Google and Facebook, while strong AI or artificial general intelligence (AGI) remains a theoretical concept and a goal which motivates the visionaries and concerns the cautious.  

# 4.2.1 History and Significance  

The true beginning, one could claim, of AI can be found in antiquity and in the writings of Aristotle and others who first started to think about reasoning and the human mind. These philosophers, and later physicists and mathematicians, were motivated by the belief that human reasoning could not only be understood and categorized, but also replicated through different machines. The Stanhope Demonstrator, for example, built by Charles Stanhope in 1775, is considered the first logical machine, capable of verifying the validity of simple deductive arguments. Attempts like these were continued to be made in the decades and centuries that followed, increasing both in complexity, reliability and utility, until the early prototypes of the modern computer started to emerge in the middle of the 20th century. The philosophy of reason and logic, and our attempt to mimic it mechanically, thus, has been, and continues to be, the main driving force of AI (Lucci & Kopec, 2016). This is perhaps where we can find the most obvious difference between normal computing, where data is processed through a program which produces a desirable and predictable output, and AI which can both collect data and processes it 'independently' by using pattern recognition, iterative learning, problem solving and  

logic, producing an output which perhaps is neither predictable nor desirable, but nonetheless the result of independent computational reasoning (Domingos, 2015).  

In the last fifty years, the development of computer science has completely revolutionized our society and everyday lives. Simultaneously, AI research has steadily been carried out although its results has not been as observable. Bostrom (2014) makes an interesting observation regarding the history of AI; drawing attention in the early stages of computing, interest in AI soon withered due to technological limits and failure to produce practically useful results. By the mid 1970s, therefore, development halted in what is called the first AI-winter. In the 1980s, interest once again began to increase but it once again failed to meet the high expectations and both funding and enthusiasm dropped and a new winter ensued. What we have seen in the last couple of years can, by any measure, be seen as a new spring, with both enthusiasm and investments skyrocketing. Perhaps this is because we now have access to the computational power and technology which is required to produce result of practical worth. To mention but a few examples, we now have semi-autonomous cars and planes, AI is used in medical diagnosis and analysis, in military security, by the UN in its work for sustainable development and so on (Kurzweil 2005, UN, 2017). Weather or not we will enter yet another AI winter remains to be seen. However, as long as research in AI yields economically beneficial results, we have every reason to believe that it will continued to develop.  

A question of particular interest, and importance, for social scientists is how will this development look like? In the introduction of this section we made a distinction between strong and weak AI. As of now, late 2017, we only have AI in a weaker, more narrow, sense, and we surely cannot predict the future. However, we can, I believe, make some valid claims about certain trends inherent in this development. One of the most essential points I want to make here is that technological progress does not follow a linear but an exponential path (figure 2).  

The easiest way to understand this difference is by looking at Moore's Law, which bears the name of Gordon Moore who predicted a twofold increase in transistors per dollar every year. Since then, Moore's Law has been used to denote the phenomenon that the computational capacity of computers doubles roughly every eighteen months in an exponential manner, instead of increasing linearly (Brynjolfsson & McAfee, 2014). What this means in practice is that we have an intuitive linear view of progress and expect that technological development will  

continue at its current rate, but if the development occurs exponentially, then our forecast of the capacity of future technologies will be gravely underestimated.  

Figure 2. Exponential vs. Linear Growth.This graph shows the difference between a linear and an exponential progression through time. The knee of the curve represent the moment when the rate increases significantly  

![](https://i.imgur.com/dv7o9D5.jpeg)  

Ray Kurzweil (2005), a renowned inventor and futurist now working for Google, claims that there is an inherent exponential component in technological and also biological development. Figure 3 below is a compilation of key milestones in human development compiled by Kurzweil and displayed on a exponential scale. I include it here because I believe it supports the remarkable trend that Kurzweil claims to be true.  

Figure 3. Key milestones in human development, interpreted and mapped by Kurzweil (2005).  

![](https://i.imgur.com/7aIHxw5.jpeg)  

![](https://i.imgur.com/kJzC15P.jpeg)  
Figure 4. Key milestones in human development interpreted and mapped by other scholars. Again we see the same exponential trend (ibid.)  

History, it seems, gives us some clues of what is to come. Kurzweil explains this phenomenon with what he calls The Law of Accelerating Returns which is a evolutionary process where positive feedback increases the rate of progress, which further increases the returns and the positive feedback and so on in a cyclical manner. The result is the exponential growth we can see in the graphs above. If this is in fact the case, then we can expect the next hundred years to bring not a hundred years of progress but rather twenty thousand years worth of progress, measured in today's rate (ibid.) The important point here is that we can expect AI to steadily increase in capability and strength, making it an increasingly important tool in our daily lives.  

This prospect has, rightfully so, gained a lot of attention lately, with people calling it the Fourth Industrial Revolution (Schmidt, 2017), Life 3.0 (Tegmark, 2017), the Second Machine Age (McAfee & Brynjolfsson, 2014) and the Transhuman Age (Jebari, 2014). However, not all agree that an AI matching och or exceeding human capabilities is even possible, and among those who believe it to be possible, there are varying opinions on when this will occur. Notwithstanding, the majority of them  

believe that it will occur sometime during this century, and probably between 2040 and 2050 (Müller & Bostrom, 2014).  

# 4.2.2 Current State and Development  

As mentioned previously, AI aided technology is already used in many fields, including medicine, the automotive industry, search engines and social media, in the business and finance sectors to mention just a few (McAfee & Brynjolfsson, 2014). Max Tegmark (2017) includes an interesting figure imagined by robotics researcher Hans Moravec which illustrates the potential of AI. Included below, figure 5 represents computer capability as a rising sea level, increasingly covering the landscape of human competence.  

Figure 5. Hans Moravec's illustration of the rising tide of the AI capacity. From Max Tegmark (2017).  

![](https://i.imgur.com/mzqlPSf.jpeg)  

As we can see, art and science are still far of from being taken over by AI, but things like driving and translation are on the verge of being mastered. Indeed, if we quickly scan the news, we can see that a lot of resources are put into these fields, ranging from Google's real-time translation earbuds (Business Insider, 2017), to investments in autonomous driving by the largest car manufactures (Investors, 2017), to reports about large Chinese companies combining forces to stay ahead in the AI race (SCMP, 2017).  

We can expect to see more investment in AI in the years to come, the primary reason is that it is economically sensible to do so. AI technology increases productivity since it requires less input (of labour for example) to produce the output necessary. An important point to be made here, which unfortunately lies outside the scope of this thesis, is the impact that an increased automation will have on the economy and, through it, our society at large. Reports forecast that half of today's  

work will be automated by the year 2055 (McKinsey & Company, 2017. Importantly, women will be disproportionately affected by this since they are overrepresented in the kinds of jobs most susceptible to automation (Hayasaki, 2017). The consequences of this development is still under debate, with some arguing that investment in human capital will be enable people to adapt to the new knowledge intensive labour market, or that increased productivity will, similar to the IT revolution, give birth to new sectors and new types of jobs which will absorb those unemployed by automation. Others claim, on the contrary, that this time its different and that new, more radical, measures are required to avoid social tension, polarization and increased inequality, for example by introducing universal basic income (Morel et al., 2011; Autor, 2015; Bergman, 2016).  

Another concern which some have expressed relates to safety issues regarding AI. Nick Bostrom is broadly regarded as the main proponent of what is knows as AI safety, which is the idea that developing a super-intelligent machine poses certain existential risks to humanity if its value system and motivation does not correspond to ours. Humans, Bostrom claims, have often failed manifold before perfecting an invention, but when it comes to super-intelligent computers we only have one chance to get it right (Bostrom, 2014; Bostrom, 2012). Relating to this, Erika Hayasaki (2017) warns us of the racism and sexism that we, perhaps unintentionally, might be building into these AI systems, since most of this research is carried out in a field dominated by men in Western countries.  

# 4.2.3 Machine Learning and Algorithms  

The big difference between AI and machine learning is that the latter is a subcategory of, or a specific method to achieve, the former. There are a couple of different approaches which have been conceived by scientists and philosophers to achieve AI, machine learning is only one possible path in this regard, along with computerized simulation of the human brain and neuromorphic engineering (Bostrom, 2014). The reason why I have chosen to focus on machine learning, however, is that it seems to be, according to the literature, the most prevalent, and promising, method in the field currently, used by the largest companies such as Google, Facebook and Microsoft (Domingos, 2015; Deepmind, 2017; Facebook, 2017; Microsoft, 2017). In the remainder of this section, I will seek to give a brief explanation of what machine learning is, in order to analyze why, and if, it matters for the democratic process.  

Machine learning depends on algorithms. An algorithm is a set of rules or sequence of instructions guiding an operation, for example a computation. A computer is made up of transistors which are either on or off, creating the binary language of zeros and ones which is the foundation of all modern computing. The most basic algorithm tells a transistor to turn on or off and this in turn represent one bit of information. Combining two transistors, we get a slightly more complex system with more possibility to store information. Changing the state of each transistor in a specific way by using instructions is called computing and this requires algorithms. A modern computers processor contains billions of these transistors which work in congruence with each other and this can be considered a type of logical reasoning. Software programs, therefore, are nothing more than a collection of algorithms telling the processor to manipulate the transistors in a specific way. The result is a repeatable and, hopefully, predictable output. Machine learning takes this process a step further by allowing the algorithms to reshape themselves based on the output they produce and the instructions of the learning algorithm which directs this process. In this way, the program writes itself.  

In a way, this resembles biological evolution, where the survival of the fittest mechanism can be regarded as the learning algorithm, reinforcing advantageous traits, and eliminating unwanted ones with every generational shift. A model of a learning algorithm is presented below in figure 6.  

![](https://i.imgur.com/hSSWjN5.jpeg)  
Figure 6. A schematic representation of machine learning. The process within the box is unsupervised inasmuch as it is not fed accurate reference data.  

As we can see, the process requires three elements, a learner, regulating parameters, and a model. We begin with the model which is a set of algorithms that process data input, creating an output. This is how all computers function. The learning element enters when the output is evaluated in relation to the goal that has been set up for it, for example maximizing a score on a game. Those algorithms in the model which are seen as beneficiary with regard to its goals are kept, while those who are seen as disruptive are removed and new parameters are created which are fed into the model which is then slightly altered. This process is repeated many times until the model is perfected. This is an example of so called unsupervised learning, which is not dependent on accurate data from humans for its learning, it learns solely on its own trials and errors (in achieving a goal set by some agent). Supervised learning aids the process described above, allowing the learner to compare the output it creates with the output which is accurate, or which it is supposed to achieve (Domingos, 2017; Tegmark, 2017)

If I have been successful in explaining the nature of machine learning, its potential and immense significance should be clear. It enables technology to build itself, to improve and develop on its own, it harvests data and maximizes its application efficiency, it invents new paths and strategies and can create new, and better, learning algorithms which increases the performance of the whole process. In short it learns from the input that it receives, either visual, audial or traditionally encoded data, and creates a program, an analysis, a interpretation, a prediction or any other output that previously demanded human labour, knowledge and creativity. What truly makes machine learning promising is that it depends on impressive computational hardware to function properly. As we have seen, technology develops in a exponential fashion, increasing in capacity, and decreasing in size and cost, thousands of times in the span of decades alone. If we are just beginning to harvest the labor done by researchers in the last century, what can we expect in the not too distant future? Here I would like to make one final point regarding technology. Todays transistors are becoming smaller and smaller and some believe that at some point they will reach their limit. However this does not mean that computers will stop improving. Kurzweil (2005) describes the advancement of technology in terms of paradigms, where the start of each technological paradigm initially is slow, followed by a fast exponential surge, and leveling out when it reaches its maximum. The paradigm is then replaced by another, improved, technology which follows the same pattern. Some researchers believe that the next paradigm shift is the introduction of  

3D transistors, which use all three dimensions in their construction compared to only two used today, increasing the computational potential in relation to size. Others believe that processors based on quantum physics will be the next paradigm. Quantum computing use quantum-mechanical phenomenon, such as electron superposition and entanglement, to create their transistors (ibid.). Needless to say, and without going into detail, this has the potential of creating processors with unimaginable power and would remain science fiction were it not for the fact that groundbreaking research is already being carried out and that D-Wave, a company specialized in quantum computing, is already delivering computers to among others Google (Crothers, 2011; D-Wave 2017). The growth predicted by Moore's Law, therefore, will with all probability continue.  

# 4.3 Elections & Campaigns  

Having covered the main tenets of AI, we now turn to the last important component defined by the research question. One of the most fundamental elements of democracy is the act of voting, which most directly determines the political landscape in a society. A free and fair election is perhaps the most tangible dimension of democracy, even though it is, as we have seen, not the only thing of importance. The purpose of this essay is to study the impact of AI on democracy, by looking at how and if it effects political campaigns. As such, it is necessary to understand not only political campaigns, but also the theoretical and normative aspects of elections as a democratic mechanism.  

Elections occur in the vast majority of the worlds countries, however far from all can be considered free and fair and therefore democratic (Hermet et al., 1978). The universal appeal of democracy is perhaps what inspires certain undemocratic regimes to create an illusion that the people is the true sovereign. Elections can also be used as an instrument of control, to keep dissident forces in check by providing a certain relief to social and political pressure (Sadiki, 2009). Elections, therefore, are not necessarily democratic, even though the two are sometimes used interchangeably. In order for elections to be considered democratic, they need to be free, fair and competitive (Hermet et al., 1978). During large parts of European history following the fall of the Western Roman Empire, sovereign authority lay with one ruler, and it was not until late 18th century, with some exceptions, that democratic ideas started to influence the power structure of the emerging nation states. In the decades and centuries that followed, power began to increasingly be  

vested in the people, and representation was, and is still, seen as a necessary mechanism for large and heterogeneous societies which aspire to be democratic (Reybrouck, 2013). Political representation in this regard has one primary ideal function: to enable decision-making which is in accordance with the general will. Elections have two main functions, to hold power accountable and to ensure its legitimacy. Political campaigns can thus be regarded as a dialogue between citizens and elected officials and a democratic institution in itself. This is the starting point underpinning this section.  

# 4.3.1 Free and competitive  

Two aspects are central if an election is to be considered democratic. The first concerns the freedom of the voter to cast a ballot on whomever he or she chooses, without hindrance, external pressure and on equal terms with everyone else. This is perhaps the most basic aspect of democracy, encapsulated by the well-known 'one man, one vote' mantra, prescribing equality and freedom in the choice of political representation. The second basic element of democratic elections is competitiveness; there needs to be a plurality of options and candidates who, on equal terms, compete for voters support. The voter needs to be presented with alternatives diverse enough for the vote to matter in political output and also have the opportunity to him- or herself run for political office (Hermet et al., 1978).  

The above criteria constitute the ideal. In reality some people and organizations will have more means, economic resources and ideological capital for example, which places them in a better position compared to their competitors (Hermet et al., 1978; Sadiki, 2009). In fact, this problem is, by some, considered to be of important magnitude. Elections, they claim, do not ensure that the executive power follows the general will but the will of a loud and powerful minority. To revitalize the democratic spirit of elections, therefore, it is necessary that deliberation takes center stage in the period preceding an election, where citizens engage in dialogue with one another and the candidates which ask for their support, in order to better understand and discover the general will and how to act in accordance with it (Gastil, 2000).  

# 4.3.2 Accountability & Legitimacy  

There is a debate among scholars on whether democracy constitutes only an instrumental value or if it contains an intrinsic value in itself (Christiano, 2003). The  

debate is perhaps less elusive when it comes to elections, which, I would claim, has primarily an instrumental value. As mentioned above, it is a mechanism, a mean to a certain democratic end, it is through it that representation is determined, officials are held accountable and legitimacy is achieved.  

Representation and accountability are two interrelated aspects of elections, the former dealing with the future and the latter dealing with the past. Political representation is determined by elections, candidates are given the mandate to represent their voters in the executive institutions. Responsibility therefore lies in future actions and behavior of the politicians. Accountability is achieved retrospectively; voters can chose to punish or reward the elected officials based on how they have acted in the previous mandate. Critics of this idea claim that politicians are not truly held accountable for their actions because voters lack the time and information needed to make informed decisions. Instead they vote out of habit, ideological reasons or superficial assessments of the economic or political state (Thomassen, 2014; Achen & Bartels, 2016; Gastil, 2000). When discussing this it is important to keep in mind that there are two broad electoral systems as noted by Ljiphart; the majoritarian system where the majority alone determines the representative and the proportional system where political representation is based on consensus. The latter part is often regarded as being more representative of the general will, since it enables more political parties to be represented and have an impact. In a majoritarian system, responsibility is clearer since power is concentrated to one candidate or party, while proportional system dilutes the distribution of responsibility. It is therefore more difficult to hold politicians responsible in a proportional system (Baldini & Pappalardo, 2009; Thomassen, 2014).  

Elections, when free and fair, legitimizes political power. Power is authority and authority can only be considered legitimate if it is founded on the consent, direct or indirect, by those over whom it applies. Democratic elections are perhaps the closest we can get to legitimate concentration of power and concentration of power is necessary for any functioning state (Bekkers & Edwards, 2007). A couple of things become important in this regard. First, the election process must be free, fair and competitive if it is to produce a legitimate government, anything else is based not on the will of the people, but on the will of a powerful minority. Second, participation is key. The degree of voter-turnout is closely interrelated with the level of legitimacy. Enlightened understanding, in the words of Dahl, also increases legitimacy; if the voters are well informed of the candidates and their policies, then their choice will  

bear more weight and their support will be more direct. However, these criterion are seldomly fully met. Participation and information is sometimes limited by socio-economic, cultural and ideological factors. Voting is made difficult or prohibited for certain groups of people, who do not always have the knowledge and the means to participate, get informed, organize and so on, creating a legitimacy deficit in many societies claiming to be democratic. Political distrust, low political participation and high turnover of elected officials are also signs of decreasing legitimacy, something that is increasingly apparent in European countries (Baldini & Pappalardo, 2009; Reybrouck, 2013).  

# 4.3.3 Campaigns  

The political campaign is a natural element in contemporary democracies. It is, as we are all aware of, during electoral campaigns that politicians leave the governmental buildings and seek to engage with the wider public in hope of gaining their support. As mentioned before, I believe this constitutes a very important element of a democracy; at least ideally we can imagine the political campaign to foster dialogue and interaction, not just between candidates and voters but between voters and communities themselves. In this deliberation, the general will is not only expressed but also discovered, altered and developed through discourse (Rose, 2005).  

Often, however, political preferences expressed through voting are not determined by rational judgements based on accurate information, but by things such as social identity and symbolic assessments. Lau and Redlawsk (2006) describe four different theoretical models which explain voter behavior: the first derives from rational choice theory and views the voter as a value-maximizing individual who uses the information available to arrive at rationally determined decisions; the second maintains that people care little about politics and instead act on the basis of social identity and cognitive consistency; the third is similar to the rational choice theory but political decisions are thought to be made under both information and time constrains, not always yielding the best choice from a value-maximizing perspective; finally, the fourth model assumes that the individual is only rational to a certain degree, and stereotypes and other cognitive shortcuts are used to come to a decision.  

Politicians are acutely aware of these models and use different strategies and techniques to influence how people vote in elections. Since the early 20th century,  

political scientists have tried to predict how people vote and why they do it. It began with surveys and later field experiments mimicking medical science, with control groups and treatment groups, focusing on communication strategies, identity, psychology, and economy in explaining voting behavior. Later it went on to controlled simulations, and with the introduction of computers, new data-processing techniques and advanced simulations (Issenberg, 2012a) This will be discussed in further detail in the next chapter.  

# 4.4 Theoretical Framework & Hypotheses  

As defined in the sections above, democracy is a process form which binding decisions are determined collectively by the members of a community. The moral justification for it is that human beings are equal in a fundamental way and that they themselves are the best judges of their interests. This implies a number of suppositions, many of which are discussed above, including accountability, legitimacy, equality, and participation. The introduction of AI in the discussion of democracy sheds new light on these elements, and this is, as previously noted, the main objective of this thesis. This section seeks to combine the insights from sections 4.1 and 4.2 in order to formulate the theoretical framework on which the empirical analysis will rely on.  

AI technology is, as we have seen, essentially a tool. Unless it reaches a general (human) level intelligence, I propose that it is epistemologically inaccurate to consider it as an entity or actor in itself. As such we need to demystify AI; it is no more than a highly sophisticated instrument used to enhance synthetic computation. This is true also when it is used in a democratic context. Its primary function in this regard is strategic in nature. By using powerful computers, sophisticated methods are employed to analyze large datasets containing information of the general population. Similar to surveys and polls, this method seeks to gain knowledge about the electorate, their preferences, their dispositions, their beliefs and attitudes. Where it differs from traditional methods however, is that it is more accurate, more extensive, more encompassing and much more capable of inferring information of individual voters, than was previously possible. For example, using information from surveys and polls, as well as political and consumer datasets and activities on social media, analysts can use machine learning to arrive at highly detailed, and accurate, knowledge about individual voters. This knowledge is not merely based on geographic and demographic information, but also on what is called psychographic  

information, which is a much more detailed and encompassing estimation of personal attributes (Kosinski et al. 2013). This will be discussed in further detail in the analysis section. For now, it is enough that we understand that AI is a tool that can be used to form strategies in political campaigns.

As mentioned in the motivation section, power is of central interest here. If AI is as powerful as the passage above claims, than it has the capacity to disrupt the power balance in a society, giving certain actors considerably more influence than others. Here we should note that the term 'power balance' is not meant to indicate that the distribution of power, in any existing society, is equal in any strict sense, certain actors have more power regardless of AI. What I mean is that there is a balance between the powerful elite and the population at large, which enables certain democratic institutions to be meaningful. The introduction of AI, I suspect, has the ability to alter this balance and thus add to the democratic deficiency. One central component for a legitimate election is, as previously noted, competitiveness, which among other things means that candidates compete for the voters' support on equal terms. This is what the V-Dem institute defines as the egalitarian principle and it stands to be threatened if some actors have a significant technological advancement. This leads to first hypothesis which this paper seeks to study:

H1: AI will skew the power-balance in the democratic election process.

Related to this, I believe the presence of AI technology will also have a significant and important effect on the public debate and political agenda. If certain actors have access to this powerful tool while others, their opponents perhaps, lack it, then they stand a better chance to influence which topics become important for the public debate. The mechanism for this is simple: by using AI to develop highly individualized micro-targeting communication based on accurate information derived from big data, actors stand a better chance to influence people's attitudes compared to those who use more traditional, and all-encompassing, advertising, for example through TV-ads and billboards. AI can also be used to test, through simulations and real-time feedback, which advertising strategies and messages resonate best with the target audience, adjusting and optimizing this continuously as new information is collected. This poses a threat the deliberative element of democracy which as we have seen, is perceived to be of central importance for the legitimacy of power. It also poses a threat to the democratic process itself, defined above as a mechanisms  

where the members of an association collectively determine the rules and laws under which they obey. This choice rests on both adequate information and on an open and free discussion based on that information. If certain actors have the capacity to influence the topics or nature of that discussion, then the subsequent choices will democratically deficient. The second hypothesis is thus as follows:  

H2: AI, as a tool, will give certain actors more power to determine the political debate and agenda.  

The difference between political marketing campaigns and propaganda is difficult to distinguish. Propaganda is the systematic and deliberate effort to influence peoples attitudes, beliefs and actions for specific purposes and goals (Propaganda, 2017). A political campaign, one could reasonably argue, fits neatly into this description. Attempts to influence the debate and agenda in a society can be viewed as one component in this effort and therefore not illegitimate in itself; it is virtually used in all political campaigns, although they vary in degree and transparency. However, can political advertising have malicious purposes? Perhaps it is easier to answer if we rephrase the question: can propaganda have malicious purposes? I think most of us would answer positively to the second question, since we understand that the objective of propaganda sometimes is to misinform, manipulate and discourage. There is nothing which limit political campaigns from using these methods if they are perceived as effective, as long as it is within judicial boundaries. Again, this is not inherently illegitimate but, on the contrary, part of our historical and political culture. We should, nonetheless, be aware and cautious of these tendencies and hold our political representatives accountable and the societal debate responsive. There are reasons to believe that AI exacerbates problems relating to these matters in at least two ways. First, individualized ads can target specific individuals with specific political messages. This might be done both in an effort to gain support for yourself and/or to slander your opponents. The problem, however, emerges when the political messages differ in relation to the receiver and when these messages contradict one-another. Another problem is that the filter-bubbles or echo-chambers in the public sphere are reinforced by these micro-targeting ads, polarizing the debate and damaging the environment for enlightened understanding.  

As we have seen, some theories propose that voting behavior is not always determined by rational consideration of available information, but on things like  

ideological identification and cognitive shortcuts. This presents a weakness in the democratic idea and gives actors the possibility to influence voters, not based on factual claims, but on emotive appeal, identity politics and the such. Machine learning makes a crucial difference in this regard, because of its sophisticated capacity to both know the individual voters, and to target them effectively. It therefore exacerbates the problems expressed above. The third hypothesis is therefore:  

H3: AI will further impede the environment for enlightened understanding.  

A second issue arising from AI enhanced 'propaganda' is that it can be used to discourage voters from casting a ballot. This can be done to either suppress voters which are believed to support an opponent or to keep certain groups from gaining political influence. Efforts to this end have undoubtedly occurred historically and there are reasons to believe that it occurs even now, although to a lesser degree and more covertly since it is, in its very essence, anti-democratic. Similar to the techniques used to affect the discussion and information environment, voters can be discouraged from voting by appealing to their emotions and cognitive condition. Again, the effect of is significantly enhanced through machine learning, primarily because it knows the individual better and is capable of making more sophisticated analyses. It can, so to speak, perfect its assault and find indirect ways to discourage voters. This leads to the fourth and final hypothesis which will be studied in this paper:  

# H4: AI can be used to depress voter turnout.  

These hypothesis rests on the criteria devised by Robert Dahl, as explained above. Central to them are issues relating to accountability, legitimacy and equality, all important to the democratic idea. Therefore they intersect and build on each other. The distinction, however, is still important because it systematizes the analysis, enabling us to focus on specific aspects of democracy which might be affected by AI technology.  

# 5. Empirical Analysis  

This section includes a comparative case study of three distinct empirical cases, where machine learning has been a central strategic instrument in the political campaign. This analysis should be understood in two, interrelated, ways. Firstly, it should be read as an initial test to the hypotheses formulated above; do they merit any empirical support? Secondly, it should be viewed as an extension of the theoretical exploration.  

# 5.1 Obama 2008 & 2012  

Algorithms were central in the 2008 Obama campaign, and its success. Elections in the U.S are intricate matters with budgets reaching many hundreds of million of dollars, campaign workers and volunteers reaching hundreds of thousands spread throughout the country's fifty states, with clear hierarchies consisting of different level managers, analysts, external polling firms, activists all organized in a robust and corporate manner. It is, therefore, those who are best organized that stand the best chance of winning. Not diminishing the role of the candidate, on whose charisma and person the campaign ultimately rests on, it is fair to say that those who make best use of the assets they posses end up on the top. This obvious fact is necessary to keep in mind when considering why algorithms were so central to Obama's 2008 campaign and his subsequent 2012 re-election.  

Political campaigns in the U.S have historically rested on information derived from polls, individual pledges, face to face meetings, telephone campaigning and so on. This information, in particular since the advent of cheap and easily accessible computers, has been stored in private and party owned databases, where the political behavior of individual voters has been tacked historically and new information has been added continuously. This has been used to say something about the voters in the database, but the voters outside remained a mystery. Ken Strasma, a targeting consultant employed by Obama in 2008, developed statistical algorithms which used information from known voters to extrapolate information about unknown voters. They mined the extensive databases to find patterns and relationships which were, in practice, impossible to carry out manually and used this information to guide the ongoing campaign. These algorithms decided on a daily basis how the campaign was to be organized, guiding political methods, the activity of volunteers and the marketing strategies, the result of which would later be re  

inserted into the database, analyzed throughout the night, interpreted in the morning and used to guide the activities the next day. This iterative process was the engine of the campaign, aided by information from outside sources such as polling and surveys, and finely tuned to the specific local context (the states and counties) where they operated. The key aim was to perfect a method called micro-targeting, where each voter is treated as a distinct and meaningful unit, and is to be targeted as such. The majoritarian system of the U.S made this extra valuable, since each district, and their delegates, were necessary to win the state, and each state was necessary to win the nomination and later the presidency. Micro-targeting was only made possible by algorithms, since they could extrapolate information on voters who were not present in the database. Predictions made by them were very close to the outcomes, and the success of the first Obama campaign can in large parts be attributed them and their interpretation (Issenberg, 2012a)

The winning recipe was again used, and refined, in the 2012 election. The staff from 2008 used the time during the first mandate to build their own, improved, algorithms. The method broke with old practices which made statistical claims based on small samples treated in different ways as representatives of certain geographical and demographical groups. Instead, as in the 2008 campaign, each voter was treated as a distinct and important unit, the information on which was collected individually when possible and derived from statistical projections when absent. But something important had occurred between the two elections, social media and smartphones had become mainstream tools. This presented a new opportunity for the campaign analysts and strategists: information could not only be directed in more refined and precise way towards individual voters, but it could also be collected more extensively. The database grew, aided by faster and cheaper computers, mobile technology which made it easier for campaign workers to report back information, and, importantly, a new infrastructure was developed uniting the different databases, which was easily accessible for the workers and richer in data.

The strategy that the campaign managers ordered was to make decisions based on empirically verified data. Furthermore, experiments, a relatively new approach in political campaigning, were introduced. Using control groups and treated targets, marketing and communication strategies were tested and the information was used to construct so called experiment-informed messages, which lacked the problems of external validity that the artificial settings of focus group approaches suffered from. They also used this system to see what political topics mattered and  

to measure how successful their ads were affecting the public debate. All this rested on algorithms and the tens of thousands of simulations carried out every night to refine them. The result was quite interesting, focusing campaign resources on seemingly obscure outlets and geographic locations which the Romney campaign could not understand, but which the algorithms showed to be of optimal importance. The affect of these marketing and communication strategies were closely monitored, evaluated through polls and surveys, and, of course, re-fed into the databases. The result was staggering, not only did Obama win the election by a large margin, but the predictions made by the campaigns analysts were impressively accurate (Issenberg, 2012b; Domingos, 2015)  

# 5.2 Brexit  

On June 23, 2016, the British people voted to exit the European Union. This surprising decision has generated a wide range of theories explaining the outcome, ranging from a deep-seated cultural-historical euroscepticism; a popular democratic protest reclaiming national sovereignty; an expression of anti-immigration sentiment; to simply being a symptom of the right-wing wave that is flushing European politics in general (Glencross, 2016). Also, Jean Seaton (2016), a professor of media history, claims that the centralization of media outlets to big cities in the UK, left a large part of the population without a voice, and a "lost sense of self" (p.333), with power being increasingly more distant, vague and non-transparent. A vote to leave was a vote to reclaim power, or a protest expressing their perceived loss of value.  

All these factors, I think, are important and merits inspection far outreaching the scope of this paper, but they do set the ground for the analysis below; we can only understand the campaign leading to the referendum through the prism of these factors. As of now, Brexit remains somewhat understudied, primarily because it is a quite recent event. Nonetheless, there have been some reports dealing with the issue of central importance to this study, namely the use of AI in the political campaign. Perhaps it is because the people opted for an EU exit, but most of what has been written on this topic, deals with the leave-side campaign, and will therefore be the main focus of this section.  

Apart from the usual mechanism present in any democratic election, AI and machine learning seem to have been an important tool used by the leave-side. Investigative journalist Carole Cadwalladr have published a number of articles in the Guardian, examining this. She claims that Cambridge Analytica (CA), a UK based  

firm which uses big-data analysis to guide political campaigns, was a central factor in the vote outcome. They, like the Obama campaign, implemented, and one might say perfected, the micro-targeting strategy, by collecting huge amounts of information about the British people, not only from their stated political views, but also from consumer datasets and social media. The latter part is of particular interest; using information from Facebook likes and other social media interactions and analyzing through machine learning techniques, they could conduct so called bio-psycho-social profiling on an individual level, and adjust their campaign accordingly. Bio-psycho-social profiling is a method developed in what is called cognitive warfare, sometimes expressed through the concept 'winning hearts and minds', and is used to change narratives, attitudes and political orientations among the civil population. This parable to the military is not only semantic.; according to Cadwalladr, Cambridge Analytica is run by actors with experience from both the UK and the US military establishment, presumably bringing their expertise and connections with them. The information was not only highly detailed on an individual level, but by using machine learning, they could extrapolate the information they had to produce information about voters they did not have. All this was used to build a communication campaign which targeted individual voters in specific ways; they diverted from simply information-based ads, to ads aimed to trigger emotive responses, knowing that this would be more successful in persuading voters (Cadwalladr, 2017a; Cadwalladr, 2017b). This is an approach that Cambridge Analytica themselves explain in detail. It consists of three parts: the first is derived from behavioral science where individuals are mapped using personality tests online and this information is then used to extrapolate information about the population as a whole, the second part combines this information together with information data-points² from social media and consumer datasets into one database, and thirdly this database uses analytical tools to gain insight into the target audience and to produce highly individualized ads, tailored specifically for the receiver (Concordia, 2016).  

As we have seen in both the Obama 2012 campaign and the Brexit campaign, social media plays a central role. In fact, social media or new media is viewed by some as a central element in a new era of propaganda, not dissimilar to the one described above (Briant, 2015; Cadwalladr, 2017b). This becomes apparent when  

you analyze the interaction of people on social media during the campaign. To mention but one example, Vyacheslav Polonski (2016), a researcher at Oxford Internet Institute, has created a visualization of the hashtags used in relation to Brexit. Figure 7 shows a semantic network consisting of 13,310 distinct hashtags, and their relational links to one another.  

![](https://i.imgur.com/WrdDC7K.jpeg)  
Figure 7. A semantic network constructed by Polonski (2016) which illustrates the magnitudes and interlinks of hashtags relating to the Brexit referendum.  

Two things are of particular importance here. First is that the online discussion is very polarized, with the two camps barely interacting at all. Second is that the leave side seems to be much bigger. Polonski's analysis shows that the leave side seems to be more organized in their communication and is in fact is twice as big as the remain side. However, this does not necessarily mean that there are more Brexit supporters on instagram, it only means that they are more outspoken and vocal about their attitudes regarding the referendum.  

This leads to the final part of this section. Possible foreign involvement, primarily from Russia, has been suggested in both the 2016 U.S presidential election and the 2017 French presidential election. The mechanism proposed is that by using biased news reporting produced by companies linked to the Russian state, like RT  

and Sputnik New, bots, or software designed to mimic human online behavior, are used to affect the political narrative and discourse and to polarize the debate (Rutenberg, 2017). This has been suspected to have occurred in the British referendum as well. A report ordered by the UK House of Commons conclude that they "do not rule out the possibility that there was foreign interference...using botnets, though we do not believe that any such interference had any material effect on the outcome of the EU referendum" (House of Commons, 2017, p.5). They also mention Russia specifically, claiming that while the "US and UK understanding of 'cyber' is predominantly technical and computer-network based...Russia and China use a cognitive approach based on understanding of mass psychology and of how to exploit individuals" (ibid). They conclude the paragraph with advice to revise the cyber security strategy in relation to elections. Some scholars and debaters say that there is clear evidence of a Russian involvement, while Facebook claims that they could not track any ads from Russian agencies in relation to the referendum, something that the Oxford Internet Institute seems to agree with (Kirkpatrick, 2017a). Even if Russia did not have an effect on the outcome, it shows a potential weakness in the election process, made possible by social media and micro-targeting cognitive warfare.  

# 5.3 U.S Presidential Election 2016  

Much like Brexit, the victory of Trump in the 2016 U.S presidential election surprised many. It seems, however, that this is not the only similarity. First, both elections seem to be a popular protest against recent social and economic developments in the countries, a rejection of establishment politics and a turn towards right wing nationalist politicians, which, it seems, have been most successful in channeling, and exploiting, this disappointment. The rhetoric is often that the large mass has been forgotten in an increasingly globalized world, nationalism, isolation and suspicion toward immigration are all brought forward as remedies to these problems (Wilson, 2017). Second, both the Trump and pro-Brexit campaign seem to have been supported by the same group of people, in particular Richard Mercer, an early AI pioneer and billionaire, but also people like Peter Thiel, a wealthy American entrepreneur and Trump supporter, and Steven Bannon, a central figure in the right wing Breitbart News Network and later strategist in president Trump's administration. Thirdly, and connected to this, the Trump campaign was largely directed with the  

help of Cambridge Analytica, the same company which was pivotal in Brexit, and in which many of the people mentioned above are involved, either as investors or as partners (Anderson & Horvath, 2017)  

Cambridge Analytica's method seem to be quite similar to the one used in the UK referendum, a winning recipe it certainly seems, and unnecessary to repeat here. However, one strategy that the Trump campaign seem to have adopted more rigorously and which is quite disconcerting from a democratic perspective, is voter suppression. According to reports, they focused on three groups which were likely Clinton supporters (white liberals, young women and African Americans) and developed ads designed to discourage them from voting. How and if this was effective is hard to measure, but the act itself is worth noting, especially if the ads, as some claim, were successful (Green & Issenberg, 2016)  

Another major difference seem to have been the presence of a bigger and more aggressive foreign involvement during the election, primarily, it is suspected, from Russia. An assessment from the three major US intelligence agencies (CIA, NSA, FBI) concludes that Russian activities in the presidential election "represent the most recent expression of Moscow's longstanding desire to undermine the US-led liberal democratic order" (ICA, 2017, p.ii) through "covert intelligence operations - such as cyber activity - with overt efforts by Russian Government agencies, state-funded media, third-party intermediaries, and paid social media users or 'trolls'" (ibid). Interestingly, they also conclude that the activities were aimed to help Trump, by harming Clinton's electability and reputation. These "trolls" that the report mention are not always human but, on the contrary, many of them are bots, designed to push certain narratives, inaccurate or unbalanced news reports, and to polarize the debate. The impact of this, because of the nature of social media, is hard to estimate, but social media analyst Jonathan Albright claims that these efforts might have been shared hundreds of millions of times (Timberg, 2017; Ferrera, 2016; Madrigal, 2017; Bunch, 2017)  

How did the Russians know which groups to target? The Trump campaign has acknowledged that big data and micro-targeting were central in their campaign, but they deny having any connections to the Russian activities. Some suspect that Cambridge Analytica and the Russian agencies had at least some communication and helped each other in electing Trump, but as of now, it remains unknown (Brannen, 2017).  

On her part, Hillary Clinton also invested heavily on sophisticated big data analysis. In fact, she seems to have been way ahead of her republican counterpart, taking lessons from the Obama campaign and, she thought, doing her homework. Her campaign managed to attract clever minds from Silicone Valley and build new datasets using information provided by the Democratic National Committee and previous campaigns, but also adding new information continuously. The data was analyzed using powerful machine learning algorithms which constituted the empirical base for many of the campaigns decisions. Also, around 400,000 simulations were run daily, in order to evaluate decisions and optimize the algorithms. This would all sound more impressive if the election had turned in her favor, with Trump as president, however, people are now pointing at some fundamental mistakes made on the back of data-intensive analyzes. First, certain states that were later understood to be key, primarily Wisconsin and Michigan, were only identified as such by the algorithms when it was too late. Second, certain strategical decisions, such as advertising celebrity endorsements and using specific phrases, turned out to be less optimal in hindsight (Lapowsky, 2016; Higgins, 2016; Wagner, 2016; Siebert, 2016). It seems that the Trump campaign, and Cambridge Analytica, had more sophisticated algorithms, which might have been decisive for the outcome.  

# 5.4 Discussion  

What conclusions can we draw from the cases above? In this section, an attempt will be made to summarize and discuss the broad themes which emerged in the cases above.  

# 5.4.1 Hypothesis 1: Power Balance  

As the cases clearly show, certain actor have indeed benefited considerably from the adaption of AI aided analysis. Big data and machine learning seem to have been pivotal both in the Trump victory and in the Brexit outcome. A telling detail in the former case shows the true value, in political terms, of this. Writing in mid 2016, journalist Issie Lapowsky (2016) writes in the somewhat patronizingly titled article Clinton Has a Team of Silicon Valley Stars. Trump Has Twitter, that Trump's only has one in-house digital director and that his chances of catching up with Clinton are 'slim'. It is easy to understand her highly inaccurate analysis: she had only the Obama campaign to look at and what Clinton did seemed to follow and improve on his recipe. What she did not know, and what has been uncovered since then, is that  

Trump used Cambridge Analytica whose methods were significantly more sophisticated than Obama's in 2012. Their approach was based on groundbreaking work from psychometrics expert Michal Kosinski and could use his methods to devise highly accurate analyzes on individual voters, as explained above (Grassegger & Krogerus, 2017). What is interesting to point out is that the primary investor and owner of this company is Richard Mercer, an outspoken right-wing billionaire which seem to have had ideological reasons for his involvement both in the U.S election and in UK referendum. One of the board members of Cambridge Analytica is Steve Bannon, also a leading right-wing politician who was instrumental in the Trump victory (Candwaldr, 2017a; Bunch, 2017). These two men, one could argue, have had one of the largest impacts on global politics in recent history, enabled to a large extent by sophisticated machine learning algorithms.  

This brings attention to other, less anonymous, actors: Google, Facebook and other companies in the IT-sector. As we all know, these companies play an indispensable role in how we communicate and receive information. We pay for these services not with money, but with information about ourselves, which they then use to sell to advertisers (Pariser, 2011). Because of their centrality in our everyday lives, they continue to collect information about us and this, I would argue, makes them immensely powerful in our contemporary world, deciding not only which books to buy or movies to see, but also which narratives to listen to and which political ideas to consider. Since these are private firms, they are harder to regulate, especially if we do not understand the magnitude of their capabilities, as the above cases show. The other side of the coin, although outside the scope of this paper, is that the same information can be used by governments to monitor and control citizens. This is seems to be the case in many authoritarian or semi-authoritarian states, but, as we have seen with the Snowden revelations, it might also be used in democratic states (Fox & Ramos, 2012; Briant, 2014).  

Using machine learning algorithms unhindered by regulation enables certain actors, those who command the technology, to gain considerable political power. Certain scholars have called it an act of "social engineering" or a "Weaponized AI Propaganda Machine" which is used to target "people individually to recruit them to an idea...by keeping them on an emotional leash" by manipulating their "opinions and behavior [in order to] advance specific political agendas" (Anderson & Horvath, 2017). The mechanisms of this, including 'fake news', echo-chambers and their automated intensification, will be discussed in further detail below, for now it is  

important that we understand that AI does not produce an unjust power structure but has the potential to further concentrate power into the hands of a minority, at least as long as it is not democratized or regulated through legislation.  

# 5.4.2 Hypothesis 2: Debate and Agenda  

One of the mechanisms through which the political power of certain actors increases using AI technology, is that which increases their impact on the public debate, and through it, the political agenda. On a macro level it is about pushing certain narratives and raise certain questions which they view as being beneficiary for their campaign, while suppressing those who they view as obstructive. The power of machine learning in this regard is its capability to target voters individually, but also to have enough information about them to devise political messages that resonate with them in particular ways and to measure this response for future adjustments. Again this is not intrinsically a bad thing, but when it is used to divert attention, to polarize the debate, or to give contradictory signals to the electorate, then it might be viewed as problematic.  

The 2016 presidential election in the United States I think provides the best example of this. According to Johnathan Albright, who studies the impact of social media on journalism and news, there exists an 'ecosystem' consisting of hundreds of right-wing news sties, cleverly connected to one another in order to manipulate search engines and, more importantly, using mainstream platforms such as Facebook and Youtube to influence the general discussion (Cadwaldr, 2016). These sites are no strangers to fake news and without an adherence to strict journalistic norms, they can and do push the societal debate in certain directions (Fox & Ramos, 2012). For example, Steve Bannon and his Breitbart News Network, a highly conservative and increasingly popular agency based in the U.S, played and instrumental role in Trump's victory, giving him both a platform to express his ideas, and the attention needed to attract votes (BBC, 2016; Strassel, 2016). The fact that they are conservative does, of course, not mean that they produce fake news, but they are, to say the least, ideologically biased. On the other hand, there are sites which can be considered to have dubious intentions. News agencies Sputnik News and RT which have direct links to the Russian government, are also producing outputs for the American news market. Considering that strong provisions of free speech in the U.S, these outlets can produce any news they like and spread them using online bots and targeting advertising. This has been called a new type of  

information war by some analysts, with the aim to disrupt fundamental state institutions and cross-national relations in the western hemisphere (Rutenberg, 2017).  

The real effect of these ecosystems and fake news outlets is hard to both confirm and determine the true effect of. However, there are reasons to believe that they polarize the debate by increasing both the prevalence and isolation of so called echo-chambers or filter-bubbles, where individuals only receive information which concur with their held beliefs and world-views (Bozdag, 2013). Thus instead of the internet being the democratic promise it once was thought to be, as a public sphere for dialogue, it becomes, through targeting algorithms, a constituent factor of segmentation and isolation. Extreme groups on either the right or the left have a vested interest in polarizing the debate, as this pushes voters closer to them. During elections, thus, it is reasonable to believe that they will try to do this, something that was evident in both the U.S presidential election and the U.K referendum (Wilson, 2016). This tendency of polarization is quite evident in the U.S, for example, as we can see in figure 8 below. The difference between 2004 and 2017 is quite staggering, and the internet is, according to some researchers, the main explanatory factor (The Economist, 2017).  

![](https://i.imgur.com/7DjMYMc.jpeg)  
Figure 8. A comparison of the ideological distance among Americans, between 1994, 2004 and 2017. From The Economist (2017).  

A final note in this section is that bots are used deliberately and, it seems, quite effectively to push certain discourses in the public debate, both by making certain (sometimes fake) news go viral and as instruments to target specific groups. A bot is  

a computer program designed to conduct certain tasks online. In this context, their primary objective is to share, like and even produce posts on social media and interact with each other in so called bot-networks or botnets, in highly systematic and deliberative ways in order to achieve whatever goal their creators set. Some of these bots are designed to be perceived as human and by using machine learning and other AI technologies, they can be quite successful in doing so (Kollanyi et al., 2016). Bots have been found to play quite a considerable role in both the U.S and the U.K case, sometimes making up a large chunk of the communication online, coming both from domestic and foreign sources (Rutenberg, 2017; Kirkpatrick, 2017a; Kirkpatrick 2017b; Timberg, 2017). As artificial intelligence increases in sophistication, we can expect that the problems identified above will become more severe, unless we put in place regulation which limits the use of these methods.  

# 5.4.3 Hypothesis 3: Enlightened Understanding  

A fundamental assumption of Dahl's (1989) moral justification for democracy is that individuals are the best judges of their interests and should therefore have the right to be a part of the collective decision process on equal terms with others. A logical conclusion that Dahl draws from this is that people, in order to know who truly represents their interests, must have an enlightened understanding of the policies under consideration and the politicians who represent them. This is, according to him, a central feature of any existing system claiming to be democratic. From the section above it is clear that AI can be used to divert and depress, skew and control the public debate and dialogue. Here we need to distinguish between information, which is legitimate, from conscious disinformation, which in a democratic sense, according to Dahl, must be essentially illegitimate.  

Spreading information is central characteristic of human civilization, form early mouth to mouth transmission of important news and gossip, to the printing press which allowed ideas to disseminate to far larger crowds than before, and to the internet and social media where the transmission, and consequently production, of information has been democratized and is shared easily, cheaply, and widely across the globe. Throughout our history, however, there has always existed fake news, manufactured by actors which stood to gain something from their proliferation. Social media and the sophistication of machine learning, allow these fake news to be spread more deliberately and effectively (Burkhardt, 2017). This seems to have been the case, as we have seen, in the 2016 U.S presidential election, with evidence  

pointing to at least Russian disinformation campaigns (Brannen, 2017; Kirkpatrick, 2017a, ICA, 2017).  

Even though there are no clear evidence of disinformation having a significant effect in the cases considered above, the mechanisms which enable and drive the proliferation of fake news are worth considering since, I believe, they can be detrimental to the democratic election process. It is a widely shared belief, at least for those who question a narrow Schumpeterian understanding of democracy, that knowledge is a fundamental element in the democratic process. It is not only necessary in order to form decisions which are in congruence with our interests, but the expression and sharing of information is also vital in the discovery and evolution of these interests (Fox & Ramos, 2012; Pariser, 2011). Disinformation, thus, does not only increase the power of certain actors, but it also limits our understanding of social, political and economic issues and, therefore, of ourselves as political creatures. This disinformation has the power to dilute accountability climate and to damage the legitimacy of power. This problem becomes even more severe when we consider how people attain their information, often in secluded echo-chambers where the only information that passes the algorithmic filters are those who reinforce held beliefs and opinions. Some have called this an "invisible autopropaganda, indoctrinating us with our own ideas, amplifying our desire for things that are familiar and leaving us oblivious to the dangers lurking in the dark territory of the unknown" (Pariser, 2011, p.13).  

# 5.4.4 Hypothesis 4: Voter Turnout  

Large data on individuals can, as should be clear from the sections above, be used to make highly detailed and accurate assessments of individuals preferences and personality traits. In fact, one study shows that a single like on Facebook can reveal quite a lot about your political preferences and similar studies have shown that interactions on pages like Wikipedia, Twitter and Google can also be used to forecast voting behavior (Kristensen et al. 2017). Further, social media behavior can be used not only to predict political behavior and preferences but also other aspects of your beliefs and personal traits, such as sexual orientation, alcohol consumption, religious affiliation, intelligence and so on (Kosinski et al., 2013). Needles to say, this type of estimation becomes even more accurate and detailed using machine learning.  

As we have seen, these statistical methods have been used for micro-targeting advertising and the spread of biased news-reporting which strengthen ideological echo-chambers. These are problematic in themselves, for the democratic threat they seem to pose. However, it can be used for an even an more sinister purpose: to dissuade voters from voting at all. This could be one tactic for actors looking to push electorate attitudes sufficiently in their favor to win political office. From the cases mentioned above, it is only in the U.S presidential election where this seems to have been the case. The ads and botnet activities online focused not so much to convince people about the merits of a candidate, as to dissuade them from voting on the candidate which best corresponded with their political beliefs. It seems that this tactic was used towards groups which were determined to be hard or even impossible to persuade, making their non-voting the best option. The method seem to have been twofold: first was to create or interact with social media groups which had no direct link to either candidate, for example African-American activist groups or American Muslim groups, and second to use a sentimental language calculated to fit the groups identity, in order to convey politically charged messages. One clear example of this is the Facebook group Blackivist, seemingly for politically active African-Americans, which spread anti-Clinton messages portraying her as unfavorable to their community and thus making them suspicious toward her politically. If effective, this leaves them with no real alternative and therefore makes them less prone to vote. A interesting tactic used in this process are so called dark posts, which are only visible to those which the creator decides are interesting. Sharing and other type of proliferation which are usually seen as highly desirable are thus abandoned in order to target individuals with at least suspicious and probably inaccurate and contentious messages (Timberg, 2017; Anderson & Horvath 2017). This could be seen as the clearest example of psychological warfare as discussed above; people are targeted not with political messages but covertly with the aim to manipulate them psychologically by reverting to emotionally provocative messages. In the age of filter bubbles and echo-chambers which hinders alternative information and critical viewpoints to get across, this can be highly problematic.

An even more unsettling aspect of this is that many of these efforts to suppress voter turnout, in the U.S case, have links to Russian agencies. Professor Albright studied only 6 of 470 Russia based social media pages, and found that their reach had tens of millions of people. The pages he studied all used the same methods as described above, they had no direct links to the Republican party, but  

were highly critical of Hillary Clinton and they were all identity-based, directed toward people with certain religious, sexual and political (right and left) orientations (Timberg, 2017). What does this mean for American democracy? If successful in dissuading people from voting, then it must be regarded as quite severe weapon, as democracy is seen as one of the fundamental pillars of American culture. But even for the democratic process itself, for the legitimacy of the institutions, this be viewed as highly damaging, not to speak about individual agency and freedom. The U.S presidential election is still a recent occurrence, and the magnitude of what is discussed here is yet to be studied. However, the mere possibility of this occurring deserves our attention, especially going forward as the technique improves and becomes even more versatile. A final note is that if this can happen in the United States, the richest and most technically advanced country on the planet, what does this mean for smaller countries which might not have the means or the knowledge to discover and combat these undemocratic methods?  

# 6. Concluding Remarks  

The motivation driving this study has been a fascination of the emerging AI technology and its effect on one of our main social and political institution, democracy. Reading about the 2012 Obama campaign and its approach involving big data and micro-targeting, sparked immense fascination but also concern; on an intuitive level there seemed to be a tension between this campaigning strategy and what we conceive to be democracy.  

The analysis has shown that my initial worry might be justified, at least to some degree. An increase in the sophistication of AI, primarily through machine learning, perfected what the Obama campaign had initiated. Through the use of rich data from social media, online personality tests, consumer datasets, traditional polling and surveys on the one side, and sophisticated machine learning analyzes on the other, companies have been able to target voters on an individual level. This does not, in itself, present a new threat to democracy, in fact manipulation can be seen as a fundamental aspect of democracy (Le Cheminant & Parrish, 2011). There is, however, reason to believe that AI has the potential to increases the power of elites in this regard. As we have seen, certain individuals seem to have played a key role in both the UK EU-referendum and the 2016 U.S presidential election, while there is well-grounded suspicion that agencies connected to the Russian state have  

tried to affect the outcome in both cases. The problem, as I see it, is not manipulation itself, but rather its evolvement in the light of AI, becoming increasingly more sophisticated and effective, while at the same concentrated to a handful of people who have the technology and the economic means to employ this technology. Two particular concerns arise from this, supported by my analysis. The first is that the novelty of the method allows actors to operate covertly, undetected by the traditional institutions, like mass-media, which are to hold power accountable. The second is that micro-targeting communication isolates the voter further, by sending out signals in congruence with already held beliefs, and often supported by confirmatory ecosystems of online (fake) news-sites, it polarizes the debate and hinders an adequate understanding of the issues at hand. This threatens core elements of democracy as described above, and considering the rate by which the technology develops, it might become increasingly harder to both identify and understand these methods as they progress.  

Notwithstanding these dim conclusions, we need to remind ourselves that technology remains morally neutral. As such, AI can be used to combat the negative trends described above, by, for example, determining the accuracy of a political message or a news-articles; identifying and exposing bots employed to push certain narratives; breaking the echo-chambers by not focusing on click-rates, but rather design algorithms that increase the knowledge and understanding of political issues; and as an analytical tool to increase the transparency of institutions and to keep representatives accountable, employed, for example, by civil society. There are startups who aspire to do just this, Avntgrd (2017) is one example, which offers strategic communication services based on AI, guided by a 'teleological code of ethics'. This is commendable, but far from enough. We cannot rely on the benevolence of private firms as this technology evolves, governments have a key role in both limiting its use through regulation, as they have done in France, for example, where individual micro-targeting is illegal (Polonski, 2017), and through information and education, lifting this increasingly potent technology into the public consciousness.  

Finally, AI, in my view, presents more opportunities than setbacks for the vast majority of us, at least in the long run. We need however, as Nick Bostrom (2012) reminds us, to be cautious moving forward. Threats to our democratic institutions is one of the concerns that recent developments evoke, but similar problems can be found when considering the effects of AI on our economic system, our military  

capabilities, our privacy and freedom, and even our existence as a species (ibid.). It therefore needs to be democratized to its fullest possible extent, enabling the development to occur in a transparent manner and in a collective spirit, for the common good, as envisioned by the beneficial-AI movement (Tegmark, 2017).  

# 7. The Prospects of AI in Political Science  

I set forth to study the sparks that might emerge in a AI - democracy interaction, and I believe that my study has shown that there at least is a possibility of conflict and that this needs to be studied further. My hope is that this thesis sparks some interest in this matter and that further research is done in the field. As mentioned above, there are reasons to believe that AI will affect every dimension of our lives and increasingly so going forward. We as social scientists need to pay attention to this development and include it in our contemporary understanding of the world. If this is, as Tegmark (2017) writes, the most important conversation of our time, then we, as political scientists, need to join the conversation and make sure that the development and implementation of AI is as transparent and as beneficial to society as possible. By doing so we join the effort of physicists, computer scientists and others who work toward this end.  

When it comes to the subject studied in this thesis, I believe there are plenty of further research prospects, both in political philosophy and positivist research. First, we need to understand conceptually the full extent of how AI will impact our democratic institutions, not just during the election process, but also as a governing tool by the political elite. This does not necessarily present a problem in mature democracies (although we should be vary of completely exempting them), but more so in emerging democratic states and definitely so in authoritarian states. For example if researchers are able to predict with considerable accuracy personal traits including sexual orientation and religious affiliation (Kosinski et al., 2013), we need to consider what kind of threat this presents to the lives and freedoms of individuals, and what we can do to combat it. Anders Ekholm (2016) makes an interesting remark in this regard, he advocates that data should be perceived as a collective good, and as such be included in the social contract in an effort to maximize its usefulness for the public good. This is an excellent topic for research, especially from a democratic point of view. Second, we need to study empirically what we conceive theoretically (and, of course, vice versa). For example, we have, as democratic  

citizens, an interest in keeping political institutions as transparent as possible, both in order to keep our representatives accountable and to keep power legitimate. Therefore, we need to study the extent to which AI is used as a tool of manipulation. Researchers should study political campaigns and bring to the light any covert operations which are dubious in nature. Also, as we have seen, external actors who aim to influence our political process now have more potent tools to do this. Researchers have a role to play in this regard, detecting these efforts and signaling them upstream to the political top. When it comes to global politics, researchers can provide the intellectual and practical tools for international organizations who work for human rights, environmental issues, democratization and so on. For example, states which use AI to oppress its population or a certain segment of it, should be exposed and brought to the surface.  

I believe that we are indeed standing before a monumental change change and the nature of the technological development that AI presents forces researchers to be observant, flexible and critical. We who have the time, the means and the knowledge to work with these issues are in a privileged position, and with this privilege also comes responsibility to work for the common good. It is is, as Noam Chomsky (1967) once wrote, "the responsibility of intellectuals".  

# References  

Albright, J. (2017). Welcome to the Era of Fake News. Media and Communication, Vol. 5 (2).

Achen, Ch. H. and Bartels, L. M. (2016). Democracy for Realists: Why Elections Do Not Produce Responsive Government. Princeton University Press, Princeton.

Utdrag från: Achen, Christopher H.,Bartels, Larry M. "Democracy for Realists". iBooks.

Anderson, B. and Horvath, B. (2017). The Rise of the Weaponized AI Propaganda Machine There's a new automated propaganda machine driving global politics: How it works and what it will mean for the future of democracy. Scout [online] Available at: https://scout.ai/story/the-rise-of-the-weaponized-ai-propaganda-machine [Accessed 21 December, 2017].

Autor, D. H. (2015). Why Are There Still So Many Jobs? The History and Future of Workplace Automation. The Journal of Economic Perspectives, Vol. 29 (3).

Avntgrd. (2017). About us. Avntgrd [online] Available at: http://www.avntgrd.com/about [Accessed 29 November, 2017].

Baggini, J. and Fosl, P. S. (2010). The philosopher's Toolkit: A Compendium of Philosophical Concepts and Methods. Second Edition. Wiley-Blackwell, West Sussex, United Kingdom.

Baldini, G. and Pappalardo, A. (2009). Elections, Electoral Systems and Volatile Voters. Palgrave Macmillan, Hampshire, England.

BBC (2016). How Breitbart became Donald Trump's favourite news site. BBC News [online] Available at: http://www.bbc.com/news/world-us-canada-37109970 [Accessed 21 December, 2017].

Bekkers, V. and Edwards, A (2007). Legitimacy and Democracy: A Conceptual Framework for Assessing Governance Practice. In Bekkers, V., Dijkstra, G., Edwards, A. and Fenger, M. (eds) Governance and the Democratic Deficit Assessing the Democratic Legitimacy of Governance Practices. Ashgate Publishing Limited, Hampshire, England.

Bergman, R. (2016). Utopia for Realists: The Case for Universal Basic Income, Open Borders, and a 15-Hour Workweek. The Correspondent, Amsterdam.

Bostrom, N. (2014). Superintelligence: Paths, Dangers, Strategie. Oxford University Press, Oxford.  

Bostrom, N. (2012). The Superintelligent Will: Motivation and Instrumental Rationality in Advanced Artificial Agents. Minds and Machines, Vol. 22 (2).

Bozdag, E. (2013). Bias in algorithmic filtering and personalization. Ethics and Information Technology, Vol. 15 (3).

Brannen, K. (2017). Connecting the Dots: Political Microtargeting and the Russia Investigation. Just Security [online] Available at: https://www.justsecurity.org/41199/connecting-dots-political-microtargeting-russia-investigation-cambridge-analytical/ [Accessed 21 December, 2017].

Briant, E. L. (2015). Allies and Audiences: Evolving Strategies in Defense and Intelligence Propaganda. The International Journal of Press/Politics, 2015, Vol. 20 (2).

Bryman, Alan. 2012. Social Research Methods. 4th. ed. Oxford University Press, Oxford.

Burkhardt, J. M (2017). How Fake News Spreads. Library Technology Reports, Vol. 53 (8).

Bunch, W. (2017). The key to the Trump-Russia scandal? Follow the data. Philadelphia Daily News (Philly) [online] Available at: http://www.philly.com/philly/columnists/will_bunch/the-key-to-the-trump-russia-scandal-follow-the-data-20170713.html [Accessed 21 December, 2017].

Business Insider (2017). We put Google's new language-translation headphones to the test with 10 different languages — here's how they did. Business Insider [online] Available at: http://nordic/businessinsider.com/google-pixel-buds-language-translation-headphones-2017-11 [Accessed 29 November, 2017].

Brynjolfsson, E. and McAfee, A. (2014). The Second Machine Age: Work, Progress, and Prosperity in a Time of Brilliant Technologies. WW Norton & Co, New York.

Cadwalladr, C. (2017a). The great British Brexit robbery: how our democracy was hijacked. The Guardian [online] Available at: https://www.theguardian.com/technology/2017/may/07/the-great-british-brexit-robbery-hijacked-democracy [Accessed 21 December, 2017].

Cadwalladr, C. (2017b). Robert Mercer: the big data billionaire waging war on mainstream media. The Guardian [online] Available at: https://www.theguardian.com/politics/2017/feb/26/robert-mercer-breitbart-war-on-media-steve-bannon-donald-trump-nigel-farage [Accessed 21 December, 2017].

Cadwalladr, C. (2016). Google, democracy and the truth about internet search. The Guardian [online] Available at: https://www.theguardian.com/technology/2016/dec/04/ google-democracy-truth-internet-search-facebook [Accessed 21 December, 2017]  

Christiano, Th. (2003). Philosophy & Democracy. Oxford University Press, Oxford.

Chomsky, N. (1967). The Responsibility of Intellectuals. Chomsky.info [online] Available at: https://chomsky.info/19670223/ [Accessed 29 November, 2017].

Concordia (2016). The Power of Big Data and Psychographics. Video Recording. Youtube Available at: https://www.youtube.com/watch?v=n8Dd5aVXLCc [Accessed 21 December, 2017].

Coppedge, M., Gerring, J., Lindberg, S. I., Skaaning, S-E. and Teorell, J. (2017). V-Dem Comparisons and Contrasts with Other Measurement Projects. Available at: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2951014## [Accessed 01 December, 2017].

Crick, B. (2002). Democracy: A Very Short Introduction. Oxford University Press, Oxford.

Crothers, B. (2011). How Intel's 3D tech redefines the transistor (FAQ). CNET [online] Available at: https://www.cnet.com/news/how-intels-3d-tech-redefines-the-transistor-faq/ [Accessed 01 December, 2017].

Cunningham, F. (2002). Theories of Democracy: A Critical Introduction. Routledge, New York.

Dahl, R. (1989). Democracy and its Critics. Yale University Press, New Haven, USA.

Deepmind (2017). Solving Intelligence Through Research. Deepmind [online] Available at: https://deepmind.com/research/ [Accessed 01 December, 2017].

Doorenspleet, R. and Pellikaan, H. (2013). Acta Politica, Vol 48 (3).

D-Wave (2017). The D-Wave 2000Q™ System. D-Wave [online] Available at: https:// www.dwavesys.com/d-wave-two-system [Accessed 01 December, 2017].

Domingos, P. (2015). The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World. Basic Books, New York.

Facebook (2017). Applied Machine Learning. Facebook [online] Available at: https:// research.fb.com/category/applied-machine-learning/ [Accessed 01 December, 2017].

Ferrera, E. (2016). How Twitter bots played a role in electing Donald Trump. Wired [online] Available at: http://www.wired.co.uk/article/twitter-bots-democracy-usa-election [Accessed 21 December, 2017].

Ford, M. (2015). Rise of the Robots: Technology and the Threat of a Jobless Future. Basic Books, New York.  

Fox, R. L. and Ramos, J. M. (2012). iPolitics: Citizens, Elections, and Governing in the New Media Era. Cambridge University Press, Cambridge.

Freedom House (2016). Methodology: Freedom in the World 2016. Freedom House [online] Available at: https://freedomhouse.org/report/freedom-world-2016/methodology [Accessed 01 December, 2017].

Gastil, J. (2000). By Popular Demand: Revitalizing Representative Democracy through Deliberative Elections. University of California Press, Berkeley.

Glaser, B. G. and Strauss, A. L. (1967). The Discovery of Grounded Theory: Strategies for Qualitative Research. Aldine Transaction, New Jersey.

Glencross, A. (2016). Why the UK Voted for Brexit: David Cameron's Great Miscalculation. Palgrave Pivot, London.

Goodin, R. E., Pettit, P. and Pogge, Th. (2007). A Companion to Contemporary Political Philosophy. Second edition, volume 1. Blackwell Publishing, Malden, USA.

Grassegger, H. and Krogerus, M. (2017). The Data That Turned the World Upside Down. Motherboard [online] Available at: https://motherboard.vice.com/en_us/article/mg9vvn/how-our-likes-helped-trump-win [Accessed 21 December, 2017].

Green, J. and Issenberg, S. (2016). Inside the Trump Bunker, With Days to Go. Bloomberg Businessweek [online] Available at: https://www.bloomberg.com/news/articles/2016-10-27/inside-the-trump-bunker-with-12-days-to-go [Accessed 21 December, 2017].

Gupta, S. (2006). The Theory and Reality of Democracy: A Case Study of Iraq. Continuum, New York.

Harari, Y. N. (2014). Sapiens: A Brief History of Humankind. Harper, New York.

Hayasaki, Erika (2017). Women vs. the Machine. Foreign Policy, Vol. 222.

Hermet, G., Rose, R., and Rouquié, A. (1978). Elections Without Choice. Macmillan Press LTD, London.

Higgins, T. (2016). Clinton Campaign Doubles Down on Data Analytics. Government Technology [online] Available at: http://www.govtech.com/data/Clinton-Campaign-Doubles-Down-on-Data-Analytics.html [Accessed 21 December, 2017].

Hindman, M. (2015). Building Better Models: Prediction, Replication, and Machine Learning in the Social Sciences. The ANNALS of the American Academy of Political and Social Science, Vol. 659 (1).  

Hoffman, J and Graham, P. (2006). Introduction to Political Theory (chapter 5). Pearson Education Limited, Harlow, UK.

House of Commons (2017). Lesson Learned from the EU Referendum. UK House of Commons, Public Administration and Constitutional Affairs Committee, Twelfth Report of Session 2016 - 2017.

ICA (2017). Background to "Assessing Russian Activities and Intentions in Recent US Elections": The Analytic Process and Cyber Incident Attribution. Intelligence Community Assessment [online] Available at: https://www.dni.gov/files/documents/ ICA_2017_01.pdf [Accessed 21 December, 2017].

IEP, 2017. Deductive and Inductive Arguments. Internet Encyclopedia of Philosophy [online] Available at: http://www.iep.utm.edu/ded-ind/ [Accessed 21 December, 2017].

Investors (2017). This Is The Big Self-Driving Milestone We've Been Waiting For. Investors Business Daily [online] Available at: https://www.investors.com/news/ google-waymo-autonomous-cars-with-passengers-no-human-driver-coming-soon/ [Accessed 29 November, 2017].

Issenberg, S. (2012a). The Victory Lab: The Secret Science of Winning Campaigns. Crown Publishers, New York.

Issenberg, S. (2012b). How Obama's Team Used Big Data to Rally Voters. MIT Technology Review [online] Available at: https://www.technologyreview.com/s/ 509026/how-obamas-team-used-big-data-to-rally-voters/ [Accessed 21 December, 2017].

Jebari, K.A. 2014. Human enhancement and technological uncertainty: Essays on the promise and peril of emerging technology. Theses in Philosophy from the Royal Institute of Technology.. Stockholm.

Kirkpatrick (2017a). Facebook Sees Little Evidence of Russian Meddling in 'Brexit' Vote. The New York Times [online] Available at: https://www.nytimes.com/ 2017/12/13/world/europe/facebook-russia-brexit-referendum.html [Accessed 21 December, 2017].

Kirkpatrick (2017b). Signs of Russian Meddling in Brexit Referendum. The New York Times [online] Available at: https://www.nytimes.com/2017/11/15/world/europe/ russia-brexit/twitter-facebook.html [Accessed 21 December, 2017].

Kollanyi, B., Howard, P. N. and Woolley, S. C. (2016). Bots and Automation over Twitter during the U.S. Election. Oxford Internet Institute, data Memo 2016.4. Oxford, UK: Project on Computational Propaganda [online] Available at: http:// comprop.oii.ox.ac.uk/wp-content/uploads/sites/89/2016/11/Data-Memo-US- Election.pdf [Accessed 21 December, 2017].  

Kristensen, J. B., Albrechtsen, T., Dahl-Nielsen E., Jensen, M., Skovrind, M. and Tobias B. (2017). Parsimonious data: How a single Facebook like predicts voting behavior in multiparty systems. PLoS One, Vol.12 (9).

Kurzweil, R. (2005). The Singularity is Near. Duckworth Overlook, London.

Lapowsky, I. (2016). Clinton Has a Team of Silicon Valley Stars. Trump Has Twitter. Wired Business [online] Available at: https://www.wired.com/2016/07/clinton-team-silicon-valley-stars-trump-twitter/ [Accessed 21 December, 2017].

Lau, R. R and Redlawsk, D. P. (2006). How Voters Decide: Information Processing during Election Campaigns. Cambridge University Press, Cambridge.

Le Cheminant, W. and Parrish, M. J. (2011). Introduction. Manipulating Democracy: A Reappraisal. In Le Cheminant, W. and Parrish, M. J. (eds). Manipulating Democracy: Democratic Theory, Political Psychology, and Mass Media. Routledge, New York.

List, Ch. and Valenti, L. (2016) The Methodology of Political Theory. Forthcoming in the Oxford Handbook of Philosophical Methodology (2016). Available at: http://personal.lse.ac.uk/list/PDF-files/MethodologyPoliticalTheory.pdf [Accessed 21 December, 2017]

Lucci, S. and Kopec, D. (2016). Artificial Intelligence in the 21st Century: A Living Introduction. Second Edition. Mercury Learning and Information, Dulles, Virginia.

Madrigal, A. C. (2017). What Facebook Did to American Democracy: And why it was so hard to see it coming. The Atlantic [online] Available at: https://www.theatlantic.com/technology/archive/2017/10/what-facebook-did/542502/ [Accessed 21 December, 2017].

McKinsey & Company (2017). A Future that Works: Automation, Employment, and Productivity. Executive Summary. McKinsey Global Institute [online] Available at: https://www.mckinsey.com/\~media/McKinsey/Global Themes/Digital Disruption/Harnessing automation for a future that works/MGI-A-future-that-works-Executive-summary.ashx [Accessed 29 November, 2017].

Microsoft (2017). Azure Machine Learning Studio. Microsoft [online] Available at: https://azure.microsoft.com/en-us/services/machine-learning-studio/ [Accessed 01 December, 2017].

Mills, A. J., Durepos, G. and Wiebe, E. (2010). Encyclopedia of Case Study Research. Volume 1. Sage Publications, Thousand Oaks, California.

Morel, N., Palier, B. and Palme, J. (2011). Social Investment as a Socially Sound Strategy for Growth. In De Vincenti, C. and D'Alema, M. (eds.). Fair, Robust and Sustainable. A Recipe for Europe's Growth. ItalianiEuropei/Foundation for European Progressive Studies, Rome.  

Müller, Vincent C. and Bostrom, Nick (2014). Future Progress in Artificial Intelligence: A Poll Among Experts. AI Matters, Vol.1(1).

Nelson, W. (2010). On Justifying Democracy. Second edition. Routledge, Abingdon, Oxon, UK.

Pariser, E. (2011). The Filter Bubble: What the Internet is Hiding from You. The Penguin Press, New York.

Peruzzotti, E. (2008). Representative Democracy As Mediated Politics: Rethinking The Links Between Representation And Participation. LSE Available at: http:// www.lse.ac.uk/internationalDevelopment/research/NGPA/Home.aspx [Accessed 01 December, 2017].

Plattner, M. F. (2005). A Skeptical Perspective. In Diamond, L. and Morlino, L. (eds.) Assessing the Quality of Democracy. John Hopkins University Press, Baltimore, USA.

Political Science. (2017). Political Science. Britannica Academic [online] Available at: http://academic.eb.com ezproxy.its.uu.se/levels/collegiate/article/political-science/ 109548 [Accessed 21 December, 2017].

Polonski, V. (2017). #MacronLeaks changed political campaigning. Why Macron succeeded and Clinton failed. World Economic Forum [online] Available at: https:// www.weforum.org/agenda/2017/05/macron泄漏s-have-changed-political- campaigning-why-macron-succeeded-and-clinton-failed [Accessed 21 December, 2017].

Polonski, V. (2016). Analysing the social media voices of the UK’s EU referendum. Medium [online] Available at: https://medium.com>@slavacm/social-media-voices-in- the-uk-s-eu-referendum-brexit-or-bremain-what-does-the-internet-say-about- ebbd7b27cf0f [Accessed 21 December, 2017].

Propaganda. (2017). Propaganda. Britannica Academic [online] Available at: http:// academic.eb.com ezproxy.its.uu.se/levels/collegiate/article/propaganda/109443 [Accessed 21 December, 2017].

Reybrock, D. V. (2013). Against Elections: The Case for Democracy. The Bodley Head, London.

Rose, Ch. (2005). How to Win Campaigns: 100 Steps to Success. Earthscan, London.

Rutenberg, J. (2017). RT, Sputnik and Russia’s New Theory of War. The New York Times [online] Available at: https://www.nytimes.com/2017/09/13/magazine/rt- sputnik-and-russias-new-theory-of-war.html [Accessed 21 December, 2017].

Sadiki, L. (2009). Rethinking Arab Democratization: Elections Without Democracy. Oxford University Press, Oxford.  

Schmidt, Volker H. (2017). Disquieting uncertainty. Three glimpses into the future. European Journal of Futures Research, Vol. 5 (1).

SCMP (2017). China's Baidu, Xiaomi in AI pact to create smart connected devices. South China Morning Post [online] Available at: http://www.scmp.com/tech/china-tech/article/2121928/chinas-baidu-xiaomi-ai-pact-create-smart-connected-devices [Accessed 29 November, 2017].

Seaton, J. (2016). Brexit and the Media. The Political Quarterly, Vol. 87( 3).

Shapiro, I. and Hacker-Cordón, C. (1999). Promises and Disappointments: Reconsidering Democracy's Value. In Shapiro, I. and Hacker-Cordón, C. (eds.) Democracy's Value. Cambridge University Press, Cambridge, UK.

Shapiro, Ian, Smith, Rogers M. and Masoud, Tarek E (2004). Introduction: problems and methods in the study of politics. In Shapiro, Ian, Smith, Rogers M. and Masoud, Tarek E (eds.). Problems and Methods in the Study of Politics. Cambridge: Cambridge University Press.

Siebert, T. (2016). Big Data Disaster: Clinton's ADA Algorithm Didn't Add Up. Media Post [online] Available at: https://www.mediapost.com/publications/article/290559/ big-data-disaster-clintons-ada-algorithm-didnt.html [Accessed 21 December, 2017].

Strassel, K. A. (2016). Steve Bannon on Politics as War; The Trump adviser talks about the winning campaign and says the political attacks against him and Breitbart News are 'just nonsense.' The Wall Street Journal [online] Available from Factiva [Accessed 21 December, 2017].

Tegmark, M. (2017). Life 3.0: Being Human in the Age of Artificial Intelligence. Alfred A. Knopf, New York.

The Economist (2017). World politics: How the world was trolling. The Economist Intelligence Unit, Available from Factiva [Accessed 21 December, 2017].

The Economist Intelligence Unit (2015). Democracy Index 2015 Democracy In an Age of Anxiety. The Economist Intelligence Unit. [online] Available at: https:// www.vabiladi.com/img/content/EIU-Democracy-Index-2015.pdf [Accessed 01 December, 2017]

Thomassen, J. (2014). Representation and Accountability. In Thomassen, J (ed) Elections and Democracy: Representation and Accountability. Oxford University Press, Oxford.

Timberg, C. (2017). Russian propaganda may have been shared hundreds of millions of times, new research says. The Washington Post [online] Available at: https://www.washingtonpost.com/news/the-switch/wp/2017/10/05/russian-propaganda-may-have-been-shared-hundreds-of-millions-of-times-new-research-says/?utm_term=.5ad17baa1fbf [Accessed 21 December, 2017].  

UN (2017). UN artificial intelligence summit aims to tackle poverty, humanity's 'grand challenges'.United Nations [online] Available at: http://www.un.org/apps/news/story.asp?NewsID=56922#.Wh8lYrSdUnU [Accessed 29 November, 2017].

Yin, R. K. (2003). Case Study Research: Design and Methods. Third edition. Sage Publications, Thousand Oaks, California.

Wagner, J. (2016). Clinton's data-driven campaign relied heavily on an algorithm named Ada. What didn't she see? The Washington Post [online] Available at: https://www.washingtonpost.com/news/post-politics/wp/2016/11/09/clintons-data-driven-campaign-relied-heavily-on-an-algorithm-named-ada-what-didnt-she-see/?utm_term=.5b2401b778e9 [Accessed 21 December, 2017].

Weale, A. (1999). Democracy. Macmillan Press LTD, London.

Wilson, G. K. Brexit, Trump and the special relationship. The British Journal of Politics and International Relations, 2017, Vol. 19(3).  