---
title: Attention Is All You Need
authors: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin
year: 2017
type: 
citekey: 2017vaswaniAttentionAllYou
---
[Zotero Link](zotero://select/items/@2017vaswaniAttentionAllYou)

# Abstract
- Transformer是一个完全基于注意力机制(attention mechanisms)的新网络结构。
- 它不使用递归(recurrence)或卷积(convolutions)。
- 它比其他序列转换模型(sequence transduction models)表现得更好。
- 它的可并行性(parallelizable)更强，需要的训练时间更少。
- Transformer 在机器翻译任务上创造了新的最先进的分数。
- 在大量和有限的 training data 中, 它都已经成功地应用于English constituency parsing(英语选区解析)。

