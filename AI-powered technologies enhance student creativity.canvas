{
	"nodes":[
		{"type":"text","text":"**Generate creative ideas**\nAI can be used to generate creative ideas by brainstorming new concepts, exploring different possibilities, and identifying patterns. This can help students to come up with new and innovative ideas for their projects.","id":"9776fb9be123cbf9","x":1057,"y":-400,"width":419,"height":180},
		{"type":"text","text":"**Provide feedback on creative projects**\nAI can be used to provide feedback on creative projects by identifying strengths and weaknesses, offering suggestions for improvement, and providing encouragement. This can help students to improve their work and make it more creative.","id":"99dbeb781de30e8a","x":1057,"y":-197,"width":419,"height":183},
		{"id":"ef87e03493d6735c","x":1640,"y":-365,"width":340,"height":110,"type":"text","text":"**Common ways**\nBrainstorm ideas for a creative, by Ask question and provide feedback"},
		{"type":"text","text":"Enhance student creativity in a variety of ways  ","id":"4deb7c44d593d4ef","x":280,"y":-151,"width":250,"height":83},
		{"type":"text","text":"**Helping students collaborate with each other**\nAI can be used to help students collaborate with each other by providing a platform for communication, sharing ideas, and giving feedback. This can help students to share their ideas with a wider audience and get feedback from others.","id":"560396171f94a29a","x":1057,"y":20,"width":419,"height":220},
		{"id":"eb523311df2435c5","x":1640,"y":-197,"width":250,"height":60,"type":"text","text":"Visual AI"},
		{"id":"014c89024082b353","x":1640,"y":-26,"width":780,"height":571,"type":"text","text":"\nwhat AI technologies intent to accept images as inputs and generate captions, classifications, and analyses?\n\nThere are several AI technologies that can accept images as inputs and generate captions, classifications, and analyses. \n\nOne such technology is image captioning, which uses **computer vision** and **natural language processing** to generate a textual description of an image[1][2]. This process involves using a deep learning classifier, such as a Convolutional Neural Network (CNN), to generate a comprehensive representation of the input image[1][2]. The generated representation is then used to predict the next sentence using a Recurrent Neural Network (RNN) and an attention-based mechanism to selectively concentrate attention on certain sections of the image[2]. \n\n**image classification**\nAnother technology is **image classification**, which uses AI to aid radiologists in multimodal breast image classification[3]. This technology involves using AI-assisted tools to navigate high-resolution tumor images to search for pathology patterns of interest[3]. \n\n**AI image analysis**\nAdditionally, AI image analysis of facial expressions can be used to determine affective state distances, such as \"neutral-pain,\" \"neutral-pleasure,\" and \"pleasure-pain\"[4]. This technology involves using image analysis software to extract feature vectors of facial expressions and dimension-reducing them to detect patterns[4]. \n\nOverall, there are several AI technologies that can accept images as inputs and generate captions, classifications, and analyses. These technologies use deep learning classifiers, such as CNNs, and natural language processing to generate descriptions of images or detect patterns in them.\n\nCitations:\n[1] https://www.semanticscholar.org/paper/a86e62a9c6a22573ca25f0a9c419880efa092202\n[2] https://www.semanticscholar.org/paper/ec1ef467328c5229f1ea10564ed881a536448c45\n[3] https://www.semanticscholar.org/paper/30f830438af42f68e0fbf57ebb526f5fc59bcd71\n[4] https://www.semanticscholar.org/paper/c6f350387eb31ce9156007c17375cbc7769f9ecf\n\nBy Perplexity at https://www.perplexity.ai/search/d54e1790-e46d-4e4d-998c-064f1f5b01ae"},
		{"id":"17c322b15f66177e","x":-140,"y":-139,"width":250,"height":60,"type":"text","text":"AI technologies"},
		{"id":"664b50a40eb47991","x":-440,"y":-139,"width":250,"height":60,"type":"text","text":"Input"},
		{"id":"b9de8017d9067110","x":-480,"y":40,"width":250,"height":60,"type":"text","text":"[[EEG]] 分析"},
		{"type":"text","text":"[[GSR]]  分析","id":"81d58570c11095b4","x":-480,"y":100,"width":250,"height":60},
		{"id":"1e3e02aa3bd84277","x":-480,"y":-20,"width":250,"height":60,"type":"text","text":"[[Sense Data]]"},
		{"id":"591e1eaaa466e7de","x":-480,"y":160,"width":250,"height":60,"type":"text","text":"Image frame"},
		{"id":"1387e4ac6689682e","x":-140,"y":70,"width":250,"height":60,"type":"text","text":"Visual AI 分析"}
	],
	"edges":[
		{"id":"17ab57e17a4cd554","fromNode":"4deb7c44d593d4ef","fromSide":"right","toNode":"9776fb9be123cbf9","toSide":"left"},
		{"id":"dedf5334e8b81656","fromNode":"4deb7c44d593d4ef","fromSide":"right","toNode":"560396171f94a29a","toSide":"left"},
		{"id":"8436590f7c605ae7","fromNode":"4deb7c44d593d4ef","fromSide":"right","toNode":"99dbeb781de30e8a","toSide":"left"},
		{"id":"fe68453463b81425","fromNode":"9776fb9be123cbf9","fromSide":"bottom","toNode":"99dbeb781de30e8a","toSide":"top"},
		{"id":"a21bdecb9c1ed690","fromNode":"9776fb9be123cbf9","fromSide":"right","toNode":"ef87e03493d6735c","toSide":"left"},
		{"id":"5123b8afd5eab198","fromNode":"9776fb9be123cbf9","fromSide":"right","toNode":"eb523311df2435c5","toSide":"left"},
		{"id":"5238a80f377c155d","fromNode":"eb523311df2435c5","fromSide":"bottom","toNode":"014c89024082b353","toSide":"top"},
		{"id":"f5d7204a6772c002","fromNode":"17c322b15f66177e","fromSide":"right","toNode":"4deb7c44d593d4ef","toSide":"left"},
		{"id":"4e838099559d2cd6","fromNode":"664b50a40eb47991","fromSide":"right","toNode":"17c322b15f66177e","toSide":"left"}
	]
}