(Source:  [csdn.net: OSMB測試結果： Testset：20240425-1 Basic Financial Q&A_dolphin-llama3:70b-CSDN博客](https://blog.csdn.net/alvincho/article/details/138488168))
Llama3:70b 表现最佳，其次是 Mixtral 和 WizardLM2 8x22b MoE，以及qwen:32b
llama3:70b 比其他 70b 型号有更好的性能
qwen:110b q4 量化的性能比 q8 稍好。 q2 较低
starling-lm:7b q4 量化比 fp16 和 q8 具有更好的性能
phi3:3.8b fp16量化比q4有更好的性能
phi3:3.8b 的性能比 phi2:2.7b 好得多
gemma:7b-v1.1 在 7b 到 13b 模型中性能最好，比 llama3:8b 好得多
qwen:32b q8和fp16量化比q4有更好的性能
gemma:2b-v1.1 比 v1.0 更好
gemma:2b-v1.1 fp16 量化优于 q8 和 q4
gemma:7b-v1.1 比 v1.0 性能更好
gemma:7b-v1.1 q8和fp16量化比q4好，q2低
dolphin-llama3:70b的性能低于原始 llama3:70b


(Source:  [github.com: osmb/data at main · alvincho/osmb](https://github.com/alvincho/osmb/tree/main/data))


| test_set | model      | correctness             | correct | incorrect |     |     |
| -------- | ---------- | ----------------------- | ------- | --------- | --- | --- |
| 2        | 20240419-7 | llama3:70b              | 0.6741  | 451       | 218 |     |
| 3        | 20240419-7 | mixtral:8x22b           | 0.5902  | 399       | 277 |     |
| 4        | 20240419-7 | qwen:32b                | 0.5399  | 365       | 311 |     |
| 5        | 20240419-7 | dbrx:132b               | 0.5253  | 364       | 329 |     |
| 6        | 20240419-7 | wizardlm2:8x22b         | 0.5222  | 353       | 323 |     |
| 7        | 20240419-7 | qwen:72b                | 0.4415  | 298       | 377 |     |
| 8        | 20240419-7 | mixtral:8x7b            | 0.4393  | 297       | 379 |     |
| 9        | 20240419-7 | gemma:7b-v1.1           | 0.4246  | 287       | 389 |     |
| 10       | 20240419-7 | zephyr:7b               | 0.3950  | 267       | 409 |     |
| 11       | 20240419-7 | llama2:70b              | 0.3772  | 255       | 421 |     |
| 12       | 20240419-7 | llama3:8b               | 0.3635  | 245       | 429 |     |
| 13       | 20240419-7 | llama2:13b              | 0.3595  | 243       | 433 |     |
| 14       | 20240419-7 | solar:10.7b             | 0.3595  | 243       | 433 |     |
| 15       | 20240419-7 | qwen:14b                | 0.3388  | 229       | 447 |     |
| 16       | 20240419-7 | deepseek-llm:67b        | 0.3373  | 228       | 448 |     |
| 17       | 20240419-7 | command-r:35b           | 0.3245  | 329       | 685 |     |
| 18       | 20240419-7 | openchat:7b             | 0.3195  | 216       | 460 |     |
| 19       | 20240419-7 | deepseek-coder:33b      | 0.3047  | 206       | 470 |     |
| 20       | 20240419-7 | llama2-uncensored:70b   | 0.2840  | 192       | 484 |     |
| 21       | 20240419-7 | mistral:v0.2            | 0.2722  | 184       | 492 |     |
| 22       | 20240419-7 | gemma:7b                | 0.2678  | 181       | 495 |     |
| 23       | 20240419-7 | mistral:7b              | 0.2678  | 181       | 495 |     |
| 24       | 20240419-7 | codellama:13b           | 0.2456  | 166       | 510 |     |
| 25       | 20240419-7 | llama2:7b               | 0.2456  | 166       | 510 |     |
| 26       | 20240419-7 | wizardlm2:7b            | 0.2382  | 161       | 515 |     |
| 27       | 20240419-7 | yi:34b                  | 0.2119  | 143       | 532 |     |
| 28       | 20240419-7 | gemma:2b                | 0.2115  | 143       | 533 |     |
| 29       | 20240419-7 | wizardlm-uncensored:13b | 0.2041  | 138       | 538 |     |
| 30       | 20240419-7 | starling-lm:7b          | 0.1982  | 134       | 542 |     |
| 31       | 20240419-7 | llama2-chinese:7b       | 0.1953  | 132       | 544 |     |
| 32       | 20240419-7 | orca2:13b               | 0.1953  | 132       | 544 |     |
| 33       | 20240419-7 | neural-chat:7b          | 0.1923  | 130       | 546 |     |
| 34       | 20240419-7 | gemma:2b-v1.1           | 0.1805  | 122       | 554 |     |
| 35       | 20240419-7 | deepseek-llm:7b         | 0.1716  | 116       | 560 |     |
| 36       | 20240419-7 | command-r-plus:104b     | 0.1637  | 166       | 848 |     |
| 37       | 20240419-7 | orca2:7b                | 0.1302  | 88        | 588 |     |
| 38       | 20240419-7 | qwen:4b                 | 0.1276  | 86        | 588 |     |
| 39       | 20240419-7 | llama2-uncensored:7b    | 0.1213  | 82        | 594 |     |
| 40       | 20240419-7 | deepseek-coder:6.7b     | 0.1124  | 76        | 600 |     |
| 41       | 20240419-7 | yi:6b                   | 0.0858  | 58        | 618 |     |
| 42       | 20240419-7 | phi:2.7b                | 0.0769  | 52        | 624 |     |
| 43       | 20240419-7 | qwen:1.8b               | 0.0518  | 35        | 641 |     |
| 44       | 20240419-7 | deepseek-coder:1.3b     | 0.0355  | 24        | 652 |     |
| 45       | 20240419-7 | qwen:0.5b               | 0.0296  | 20        | 656 |     |
| 46       | 20240419-7 | wizard-math:13b         | 0.0066  | 1         | 151 |     |
| 47       | 20240419-7 | falcon:40b              | 0.0000  | 0         | 338 |     |
| 48       | 20240419-7 | qwen-chat:7b            | 0.0000  | 0         | 676 |     |